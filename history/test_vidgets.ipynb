{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eed5ca0-1375-412e-8393-3e33ca8e1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import mpld3\n",
    "import os\n",
    "import webbrowser\n",
    "import matplotlib\n",
    "import mplcursors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "import networkx as nx\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pychow import chow_test\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "import networkx as nx\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pychow import chow_test\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan, het_goldfeldquandt, het_arch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, VBox, HBox\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab00618-150a-4b3c-bff8-ff1a355349e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_01_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3543c8e4-22a6-4896-bff6-874b79cfddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['indicator_name'] != \"Смертность населения (без показателя смертности от внешних причин)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a12f0dc-da8f-4810-98ef-c6c431fd66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    df1 = df1[['indicator_name', 'object_name', 'object_level', 'year', 'indicator_value', 'indicator_unit']]\n",
    "    assert(all([df1['year'].value_counts().values[i] == len(df1['object_name'].unique()) for i in range(len(df1['year'].value_counts().values))]))\n",
    "    assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1802c4c-f396-4486-81a0-de48af27b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b01adf6-0beb-4877-bd98-c3eff0e84de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# все пропуски помечены как np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1adbcee0-3f9b-46cf-bcd9-a75b4ffbfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем года\n",
    "Население = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec6d041-d463-40fa-91a2-9110ae45d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Население.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # собсвтенно генерация датасета для значения в словаре\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # проверка, что все регионы были включены \n",
    "    assert(len(new_df) == 96)\n",
    "    Население[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in Население.keys():\n",
    "    total.update(set(Население[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af393c8d-43c7-4448-9e82-71f652c67fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_02_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacc86d7-f58e-484f-9313-2c6313b6cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_cols = np.array([k for k, v in df['indicator_name'].value_counts().items() if v == 2208])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7074fe4-ae66-42be-aa7e-e31985530935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['indicator_name'].isin(needed_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "612ceb2f-389f-4582-b678-6d4325ee6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    df1 = df1[['indicator_name', 'object_name', 'object_level', 'year', 'indicator_value', 'indicator_unit']]\n",
    "    assert(all([df1['year'].value_counts().values[i] == len(df1['object_name'].unique()) for i in range(len(df1['year'].value_counts().values))]))\n",
    "    assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6986959a-f5ba-4ecc-bb84-b73a3402f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb2fe09-8fe8-41f2-b5c0-f92f50c9ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# все пропуски помечены как np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba119cf-d84e-45cd-b49a-b24c8a82ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем года\n",
    "Труд = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abaf5f60-4155-4eab-a523-2de7efe85129",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Труд.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # собсвтенно генерация датасета для значения в словаре\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # проверка, что все регионы были включены \n",
    "    assert(len(new_df) == 96)\n",
    "    Труд[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in Труд.keys():\n",
    "    total.update(set(Труд[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec6909d-6168-4fa2-a4c1-57a8dae03133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_04_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d4244e4-1d68-4747-a6c4-7b55224e4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только признаки реленвантные в 2000 году\n",
    "needed = df[df['year'] == 2000]['indicator_name'].unique()\n",
    "df = df[df['indicator_name'].isin(needed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e8e58fa-491d-4a73-baa5-c66fa1df619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# все пропуски помечены как np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb7cc5d-c358-4cae-87a2-eec6da3ec74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    if (len(df1['year'].unique()) == 23):\n",
    "        df1 = df1[['indicator_name', 'object_name', 'year', 'indicator_value', 'indicator_unit']]\n",
    "        df1['indicator_value'] = df1['indicator_value'].where(df1['indicator_value'] >= 0, np.nan)\n",
    "        assert(sorted(df1['year'].unique()) == [i for i in range(2000, 2023, 1)])\n",
    "        assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "        dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc05ddb2-8a6f-48e3-b6b0-4dfd09291c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем года\n",
    "Образование = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8c2a23-341c-4e3d-b474-1b25fda8d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Образование.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # собсвтенно генерация датасета для значения в словаре\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # проверка, что все регионы были включены \n",
    "    assert(len(new_df) == 96)\n",
    "    Образование[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in Образование.keys():\n",
    "    total.update(set(Образование[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c360c68-5c8f-4b25-bbf4-564a97b87d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выкидываем пропуски\n",
    "def drop_missing_values(df, reference_columns):\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned = df_cleaned[reference_columns]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "def normalized_dict_by_minmax(dict_of_years: dict[int, pd.DataFrame]):\n",
    "    neutral = (\n",
    "        'object_name',\n",
    "        'object_level',\n",
    "        'year'\n",
    "    )\n",
    "\n",
    "    normilized_dict = {}\n",
    "    for year in dict_of_years.keys():\n",
    "        normilized_dict[year] = dict_of_years[year].copy()\n",
    "        for category in normilized_dict[year].columns:\n",
    "            if category in neutral:\n",
    "                continue\n",
    "            normilized_dict[year][category] = (normilized_dict[year][category] - normilized_dict[year][category].min()) / (normilized_dict[year][category].max() - normilized_dict[year][category].min())\n",
    "    return normilized_dict\n",
    "\n",
    "def normalized_dict_by_minmax_by_base_year(dict_of_years: dict[int, pd.DataFrame], base_year=2010):\n",
    "    min_values_by_features = {}\n",
    "    max_values_by_features = {}\n",
    "    neutral = (\n",
    "        'object_name',\n",
    "        'object_level',\n",
    "        'year'\n",
    "    )\n",
    "\n",
    "    for category in dict_of_years[base_year].columns:\n",
    "        if category in neutral:\n",
    "            continue\n",
    "        min_values_by_features[category] = dict_of_years[base_year][category].min()\n",
    "        max_values_by_features[category] = dict_of_years[base_year][category].max()\n",
    "\n",
    "    normilized_dict = {}\n",
    "    for year in dict_of_years.keys():\n",
    "        normilized_dict[year] = dict_of_years[year].copy()\n",
    "        for category in normilized_dict[year].columns:\n",
    "            if category in neutral:\n",
    "                continue\n",
    "            normilized_dict[year][category] = (normilized_dict[year][category] - min_values_by_features[category]) / (max_values_by_features[category] - min_values_by_features[category])\n",
    "    return normilized_dict\n",
    "\n",
    "def calculate_index_with_weights(dict_of_dataframes, way_of_calculating=1):\n",
    "    '''\n",
    "    Вычисляет индекс на основе заданных данных и выбранного метода расчета весов.\n",
    "\n",
    "    Параметры:\n",
    "    dict_of_dataframes (dict): Словарь, где ключи - годы, а значения - DataFrame с данными.\n",
    "    way_of_calculating (int): Метод расчета весов:\n",
    "        1 - PCA (анализ главных компонент);\n",
    "        2 - Обратная дисперсия;\n",
    "        3 - Равные веса.\n",
    "\n",
    "    Возвращает:\n",
    "    tuple: Кортеж, содержащий DataFrame с индексами по годам и массив весов.\n",
    "    '''\n",
    "    \n",
    "    indexed_data = {}\n",
    "    combined_data = pd.concat(dict_of_dataframes.values())\n",
    "    numerical_columns = combined_data.drop(columns=['object_name', 'object_level', 'year'])\n",
    "\n",
    "    if way_of_calculating == 1:  # PCA\n",
    "        pca = PCA(n_components=1)\n",
    "        pca.fit(numerical_columns)\n",
    "        weights = np.abs(pca.components_[0])\n",
    "        weights /= weights.sum()\n",
    "    \n",
    "    elif way_of_calculating == 2:  # Обратная дисперсия\n",
    "        variances = numerical_columns.var()\n",
    "        weights = 1 / variances\n",
    "        weights /= weights.sum()\n",
    "    \n",
    "    else:  # Равные веса\n",
    "        num_columns = numerical_columns.shape[1]\n",
    "        weights = np.ones(num_columns) / num_columns\n",
    "    \n",
    "    for year, df in dict_of_dataframes.items():\n",
    "        numerical_columns = df.drop(columns=['object_name', 'object_level', 'year'])\n",
    "        weighted_mean = (numerical_columns * weights).sum(axis=1)\n",
    "        df['index'] = weighted_mean\n",
    "        indexed_data[year] = df[['object_name', 'index']]\n",
    "    \n",
    "    combined_index = pd.DataFrame()\n",
    "    for year, df in indexed_data.items():\n",
    "        df = df.set_index('object_name')['index']\n",
    "        combined_index[year] = df\n",
    "\n",
    "    return combined_index, weights\n",
    "\n",
    "def combine_indices(df1, df2, alpha):\n",
    "    if not df1.shape == df2.shape:\n",
    "        raise ValueError(\"Датафреймы должны иметь одинаковую структуру (размеры и индексы).\")\n",
    "    if not (df1.index.equals(df2.index) and df1.columns.equals(df2.columns)):\n",
    "        raise ValueError(\"Датафреймы должны иметь одинаковые индексы и столбцы.\")\n",
    "\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"Alpha должен быть в пределах от 0 до 1.\")\n",
    "\n",
    "    combined_df = alpha * df1 + (1 - alpha) * df2\n",
    "    return combined_df\n",
    "\n",
    "def plot_index_trends_multi(dfs_by_base, dfs_by_current, dfs_final, region, domen):\n",
    "    if not (dfs_by_base.index.equals(dfs_by_current.index) and dfs_by_current.index.equals(dfs_final.index)):\n",
    "        raise ValueError(\"Индексы регионов должны совпадать во всех датасетах.\")\n",
    "    \n",
    "    region_name = region\n",
    "    base_index = dfs_by_base.loc[region]\n",
    "    current_index = dfs_by_current.loc[region]\n",
    "    final_index = dfs_final.loc[region]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(final_index.index, final_index.values, marker='o', linestyle='-', linewidth=3,\n",
    "             label=\"Final Index\", color='red', alpha=0.9)  # Основной индекс\n",
    "    plt.plot(base_index.index, base_index.values, marker='o', linestyle='--', linewidth=2,\n",
    "             label=\"Base Index\", color='blue', alpha=0.5)\n",
    "    plt.plot(current_index.index, current_index.values, marker='o', linestyle=':', linewidth=2,\n",
    "             label=\"Current Index\", color='green', alpha=0.5)\n",
    "    plt.title(f\"{domen}. Динамика индексов по годам для региона: {region_name}\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"Год\", fontsize=14)\n",
    "    plt.ylabel(\"Индекс\", fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    for i in range(len(final_index)):\n",
    "        plt.annotate(f\"{final_index.values[i]:.2f}\", \n",
    "                     (final_index.index[i], final_index.values[i]),\n",
    "                     textcoords=\"offset points\", \n",
    "                     xytext=(0,10), \n",
    "                     ha='center', fontsize=10, color='red')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_facecolor('#f9f9f9')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_index_trends_with_similar(dfs_by_base, dfs_by_current, dfs_final, region_name, domen, k=3):\n",
    "    if not (dfs_by_base.index.equals(dfs_by_current.index) and dfs_by_current.index.equals(dfs_final.index)):\n",
    "        raise ValueError(\"Индексы регионов должны совпадать во всех датасетах.\")\n",
    "    if region_name not in dfs_final.index:\n",
    "        raise ValueError(f\"Регион '{region_name}' отсутствует в данных.\")\n",
    "    target_vector = dfs_final.loc[region_name].values.reshape(1, -1)\n",
    "    distances = cdist(target_vector, dfs_final.values, metric='euclidean').flatten()\n",
    "    similar_indices = np.argsort(distances)[1:k + 1]\n",
    "    similar_regions = dfs_final.index[similar_indices]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.gca().set_facecolor('white') \n",
    "    plt.grid(color='lightgrey', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.plot(dfs_final.columns, dfs_final.loc[region_name], \n",
    "             marker='o', linestyle='-', linewidth=3, label=f\"{region_name} (Target)\", \n",
    "             color='orange', alpha=0.9, zorder=5) \n",
    "    \n",
    "    colors = ['#FF6347', '#4682B4', '#32CD32', '#FFD700', '#8A2BE2']\n",
    "    \n",
    "    for i, similar_region in enumerate(similar_regions):\n",
    "        plt.plot(dfs_final.columns, dfs_final.loc[similar_region], \n",
    "                 marker='s', linestyle=':', linewidth=2, label=similar_region,\n",
    "                 color=colors[i % len(colors)], alpha=0.8)\n",
    "\n",
    "        max_value = dfs_final.loc[similar_region].max()\n",
    "        min_value = dfs_final.loc[similar_region].min()\n",
    "        max_index = dfs_final.loc[similar_region].idxmax()\n",
    "        min_index = dfs_final.loc[similar_region].idxmin()\n",
    "        \n",
    "        plt.scatter(max_index, max_value, color=colors[i % len(colors)], s=100, zorder=10, edgecolor='black', marker='o')\n",
    "        plt.scatter(min_index, min_value, color=colors[i % len(colors)], s=100, zorder=10, edgecolor='black', marker='^')\n",
    "\n",
    "    max_value_target = dfs_final.loc[region_name].max()\n",
    "    min_value_target = dfs_final.loc[region_name].min()\n",
    "    max_index_target = dfs_final.loc[region_name].idxmax()\n",
    "    min_index_target = dfs_final.loc[region_name].idxmin()\n",
    "    plt.scatter(max_index_target, max_value_target, color='orange', s=100, zorder=10, edgecolor='black', marker='o', label='Максимум')\n",
    "    plt.scatter(min_index_target, min_value_target, color='orange', s=100, zorder=10, edgecolor='black', marker='^', label='Минимум')\n",
    "    plt.title(f\"{domen}. Динамика индексов для региона '{region_name}' и {k} похожих регионов\", fontsize=18, fontweight='bold', color='#333')\n",
    "    plt.xlabel(\"Год\", fontsize=14)\n",
    "    plt.ylabel(\"Индекс\", fontsize=14)\n",
    "    \n",
    "    plt.legend(fontsize=12, loc=\"best\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_successful_regions_dynamic(dfs_final, domen, top_n=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Строит горизонтальную диаграмму топ-N самых успешных регионов, учитывая уровень индекса за последний год и динамику.\n",
    "    Добавлены декоративные элементы для улучшения визуализации.\n",
    "    \n",
    "    Args:\n",
    "        dfs_final (pd.DataFrame): Датафрейм с индексами регионов (индексы - регионы, колонки - годы).\n",
    "        top_n (int): Количество самых успешных регионов для отображения.\n",
    "        alpha (float): Вес для динамики (0 <= alpha <= 1). \n",
    "                       Вес уровня последнего года = 1 - alpha.\n",
    "    \"\"\"\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"Параметр alpha должен быть в диапазоне от 0 до 1.\")\n",
    "    \n",
    "    index_growth = dfs_final.diff(axis=1).mean(axis=1)\n",
    "    last_year = dfs_final.columns[-1]\n",
    "    last_year_index = dfs_final[last_year]\n",
    "    combined_score = alpha * index_growth + (1 - alpha) * last_year_index\n",
    "    top_regions = combined_score.sort_values(ascending=False).head(top_n)\n",
    "    norm = plt.Normalize(min(top_regions), max(top_regions))\n",
    "    cmap = matplotlib.colormaps['coolwarm']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))  # Создаем ось ax\n",
    "    bars = ax.barh(top_regions.sort_values().index, top_regions.sort_values(), color=cmap(norm(top_regions.sort_values())))\n",
    "    \n",
    "    for bar in bars:\n",
    "        bar.set_edgecolor('black')\n",
    "        bar.set_linewidth(1.5) \n",
    "        for i, (region, value) in enumerate(zip(top_regions.sort_values().index, top_regions.sort_values())):\n",
    "            ax.text(value + 0.01, i, f\"({value:.3f})\", va='center', fontsize=12, color='black', weight='bold')\n",
    "    \n",
    "    ax.set_title(f\"{domen}. Топ-{top_n} самых успешных регионов с учетом динамики ({last_year})\", fontsize=16, weight='bold')\n",
    "    ax.set_xlabel(\"Куммулятивный рейтинг\", fontsize=14)\n",
    "    ax.set_ylabel(\"Регионы\", fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bottom_successful_regions_dynamic(dfs_final, domen, bottom_n=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Строит горизонтальную диаграмму bottom-N наименее успешных регионов, учитывая уровень индекса за последний год и динамику.\n",
    "    Добавлены декоративные элементы для улучшения визуализации.\n",
    "    \n",
    "    Args:\n",
    "        dfs_final (pd.DataFrame): Датафрейм с индексами регионов (индексы - регионы, колонки - годы).\n",
    "        bottom_n (int): Количество наименее успешных регионов для отображения.\n",
    "        alpha (float): Вес для динамики (0 <= alpha <= 1). \n",
    "                       Вес уровня последнего года = 1 - alpha.\n",
    "    \"\"\"\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"Параметр alpha должен быть в диапазоне от 0 до 1.\")\n",
    "    \n",
    "    index_growth = dfs_final.diff(axis=1).mean(axis=1)\n",
    "    last_year = dfs_final.columns[-1]\n",
    "    last_year_index = dfs_final[last_year]\n",
    "    combined_score = alpha * index_growth + (1 - alpha) * last_year_index\n",
    "    \n",
    "    bottom_regions = combined_score.sort_values(ascending=True).head(bottom_n)\n",
    "    norm = plt.Normalize(min(bottom_regions), max(bottom_regions))\n",
    "    cmap = matplotlib.colormaps['Reds']  # Используем цветовую схему для негативных результатов\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    bars = ax.barh(bottom_regions.sort_values(ascending=False).index, \n",
    "                   bottom_regions.sort_values(ascending=False), \n",
    "                   color=cmap(norm(bottom_regions.sort_values(ascending=False))))\n",
    "    \n",
    "    for bar in bars:\n",
    "        bar.set_edgecolor('black')\n",
    "        bar.set_linewidth(1.5) \n",
    "        for i, (region, value) in enumerate(zip(bottom_regions.sort_values(ascending=False).index, \n",
    "                                                bottom_regions.sort_values(ascending=False))):\n",
    "            ax.text(value + 0.01, i, f\"({value:.3f})\", va='center', fontsize=12, color='black', weight='bold')\n",
    "    \n",
    "    ax.set_title(f\"{domen}. Топ-{bottom_n} наименее успешных регионов с учетом динамики ({last_year})\", \n",
    "                 fontsize=16, weight='bold', color='darkred')\n",
    "    ax.set_xlabel(\"Кумулятивный рейтинг\", fontsize=14)\n",
    "    ax.set_ylabel(\"Регионы\", fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mean_weight(weights_by_base, weights_by_current, alpha=0.9):\n",
    "    return weights_by_base * alpha + (1 - alpha) * weights_by_current\n",
    "\n",
    "def count_impact_per_component(df : pd.DataFrame, weights : np.array):\n",
    "    '''\n",
    "    Функция принимает два аргумента:\n",
    "        df : текущий датафрейм\n",
    "        weights : веса для признаков\n",
    "    Return:\n",
    "        Умножаем веса на значения признаков\n",
    "    '''\n",
    "    buff_df = df.copy()\n",
    "    buff_df.iloc[:,3:-1] = buff_df.iloc[:,3:-1] * weights \n",
    "    return buff_df\n",
    "\n",
    "def combine_for_weights_and_importances(dfs1, dfs2, index_share):\n",
    "    '''\n",
    "    Функция принимает два датафрейма и коэффициент сглаживания\n",
    "    Нужна, чтобы вычислять важность признака в структуре финального индекса\n",
    "    Возвращает важность каждого признака в долях\n",
    "    '''\n",
    "    dfs_final = {}\n",
    "    for year in dfs1.keys():\n",
    "        dfs_final[year] = dfs1[year].copy()\n",
    "        dfs_final[year].iloc[:,3:-1] = dfs_final[year].iloc[:,3:-1] * index_share + dfs2[year].iloc[:,3:-1] * (1-index_share)\n",
    "        total_sum = dfs_final[year].iloc[:,3:-1].sum(axis=1)\n",
    "        dfs_final[year] = dfs_final[year].drop('index', axis=1)\n",
    "        for col in dfs_final[year].columns[3:]:\n",
    "            dfs_final[year][col] /= total_sum\n",
    "    return dfs_final\n",
    "\n",
    "def rank_importances(clear_domen, domen, importances_of_domen, region, year):\n",
    "    if isinstance(year, list):\n",
    "        start = year[0]\n",
    "        end = year[1]\n",
    "        df = importances_of_domen[start][importances_of_domen[start]['object_name'] == region].iloc[:,3:].transpose()\n",
    "        df.columns = ['Влияние на ИРР']\n",
    "        for year in range(start+1, end+1, 1):\n",
    "            chosen = importances_of_domen[year][importances_of_domen[year]['object_name'] == region].iloc[:,3:].transpose()\n",
    "            chosen.columns = ['Влияние на ИРР']\n",
    "            df += chosen\n",
    "        df['Влияние на ИРР'] = df['Влияние на ИРР'] / (end - start + 1)\n",
    "        df = df.sort_values(by='Влияние на ИРР', ascending=False) \n",
    "        return df\n",
    "    else:   \n",
    "        chosen = importances_of_domen[year][importances_of_domen[year]['object_name'] == region].iloc[:,3:].transpose()\n",
    "        chosen.columns = ['Влияние на ИРР']\n",
    "        values = clear_domen[year][clear_domen[year]['object_name'] == region].iloc[:, 3:].transpose()\n",
    "        values.columns = ['Значение показателя']\n",
    "        chosen = pd.concat([chosen, values], axis=1)\n",
    "        chosen = chosen.sort_values(by='Влияние на ИРР', ascending=False)\n",
    "\n",
    "        category = {'Положительно' : [], 'Отрицательно' : []}\n",
    "        clear = clear_domen[year][clear_domen[year]['object_name'] == region].iloc[:,3:]\n",
    "        modified = domen[year][domen[year]['object_name'] == region].iloc[:,3:]\n",
    "\n",
    "        for col in clear.columns:\n",
    "            if clear[col].values == modified[col].values:\n",
    "                category['Положительно'].append(col)\n",
    "            else:\n",
    "                category['Отрицательно'].append(col)\n",
    "        chosen['Тип показателя'] = chosen.index.to_series().apply(\n",
    "            lambda x: 'Стимулянт' if x in category['Положительно'] else 'Дестимулянт'\n",
    "        )\n",
    "\n",
    "        # гарантия нормировки\n",
    "        total = chosen['Влияние на ИРР'].sum()\n",
    "        chosen['Влияние на ИРР'] = np.abs(chosen['Влияние на ИРР']) / total\n",
    "        chosen = chosen.sort_values(by='Влияние на ИРР', ascending=False)\n",
    "        \n",
    "        return chosen\n",
    "\n",
    "def ravel_domen_final(data):\n",
    "    '''\n",
    "    data: pd.DataFrame\n",
    "    Вытягиевает в формате столбцов: год, регион, значение индекса\n",
    "    '''\n",
    "    data = data.reset_index()\n",
    "    melted_data = data.melt(id_vars=[data.columns[0]], \n",
    "                             var_name='год', \n",
    "                             value_name='значение индекса')\n",
    "    \n",
    "    melted_data.rename(columns={data.columns[0]: 'регион'}, inplace=True)\n",
    "    \n",
    "    return melted_data\n",
    "\n",
    "def ravel_domen_dict(data_dict):\n",
    "    '''\n",
    "    data_dict: dict\n",
    "    Словарь, где ключи - годы, значения - DataFrame с колонками: object_name, object_level, year и другие признаки.\n",
    "    \n",
    "    Возвращает объединенный DataFrame с колонками: год, object_name, object_level и остальные признаки.\n",
    "    '''\n",
    "    df_list = []\n",
    "    \n",
    "    for year, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"DataFrame for year {year} is empty.\")\n",
    "        if not all(col in df.columns for col in ['object_name', 'object_level', 'year']):\n",
    "            raise ValueError(f\"DataFrame for year {year} is missing required columns.\")\n",
    "        \n",
    "        df['year'] = year\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def analyze_indicator(df, agg_func=\"mean\", region=None):\n",
    "    \"\"\"\n",
    "    Интерактивно анализирует динамику показателя по годам, с возможностью фильтрации по региону.\n",
    "\n",
    "    :param df: Dict[int : pd.DataFrame]\n",
    "    :param agg_func: \"mean\" (по умолчанию) или \"median\" - метод агрегирования\n",
    "    :param region: Название региона (или None, чтобы смотреть по всем)\n",
    "    \"\"\"\n",
    "    # 1️⃣ Фильтрация по региону, если указан\n",
    "    df = ravel_domen_dict(df)\n",
    "    if region:\n",
    "        df = df[df[\"object_name\"] == region]\n",
    "\n",
    "    # 2️⃣ Выбор показателя\n",
    "    indicators = df.columns[3:]  # Все столбцы после 'year'\n",
    "    print(\"\\nВыберите показатель для анализа:\")\n",
    "    for i, col in enumerate(indicators, 1):\n",
    "        print(f\"{i}) {col}\")\n",
    "\n",
    "    choice = int(input(\"\\nВведите номер показателя: \")) - 1\n",
    "    indicator = indicators[choice]\n",
    "\n",
    "    # 3️⃣ Агрегация данных (по годам)\n",
    "    if agg_func == \"mean\":\n",
    "        df_grouped = df.groupby(\"year\")[indicator].mean()\n",
    "    elif agg_func == \"median\":\n",
    "        df_grouped = df.groupby(\"year\")[indicator].median()\n",
    "    else:\n",
    "        raise ValueError(\"Неверное значение agg_func. Используйте 'mean' или 'median'.\")\n",
    "\n",
    "    # 4️⃣ Расчет стандартного отклонения для доверительного интервала\n",
    "    df_std = df.groupby(\"year\")[indicator].std()\n",
    "\n",
    "    # 5️⃣ Автоматический тренд (линейная регрессия)\n",
    "    years = df_grouped.index.values\n",
    "    y_values = df_grouped.values\n",
    "\n",
    "    # Выполнение линейной регрессии\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(years, y_values)\n",
    "\n",
    "    # Проверка значимости коэффициента наклона\n",
    "    if p_value < 0.05:  # Уровень значимости 0.05\n",
    "        trend_slope = slope\n",
    "        if trend_slope > 0:\n",
    "            trend = \"Восходящий 📈\"\n",
    "        elif trend_slope < 0:\n",
    "            trend = \"Нисходящий 📉\"\n",
    "    else:\n",
    "        trend = \"Стационарный ➖\"\n",
    "\n",
    "    region_str = f\" ({region})\" if region else \" (по всем регионам)\"\n",
    "    print(f\"\\n📊 Тренд показателя '{indicator}'{region_str}: {trend}\")\n",
    "\n",
    "    # 6️⃣ Темпы роста (% изменения от прошлого года)\n",
    "    df_pct_change = df_grouped.pct_change() * 100\n",
    "\n",
    "    # 7️⃣ Топ-3 года по значению\n",
    "    top_years = df_grouped.nlargest(3)\n",
    "    print(\"\\n🏆 Топ-3 года по показателю:\")\n",
    "    print(top_years)\n",
    "\n",
    "    # 🔹 Визуализация 🔹\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # --- Первый график: Динамика показателя ---\n",
    "    axes[0].plot(df_grouped.index, df_grouped.values, marker=\"o\", label=\"Динамика показателя\", color=\"b\")\n",
    "    axes[0].plot(years, intercept + slope * years, linestyle=\"dashed\", color=\"red\", label=\"Линия тренда\")\n",
    "    axes[0].fill_between(df_grouped.index, df_grouped - df_std, df_grouped + df_std, color=\"gray\", alpha=0.2)\n",
    "\n",
    "    axes[0].set_xlabel(\"Год\")\n",
    "    # axes[0].set_title(f\"Динамика показателя: {indicator}{region_str}\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # --- Второй график: Темпы роста (столбиками) ---\n",
    "    colors = [\"green\" if val >= 0 else \"red\" for val in df_pct_change.values]\n",
    "\n",
    "    bars = axes[1].bar(df_pct_change.index, df_pct_change.values, color=colors, alpha=0.7)\n",
    "\n",
    "    # 🔢 Добавление значений над столбцами\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if not np.isnan(height):  # Проверка, чтобы не писать NaN\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, height, f\"{height:.1f}%\", \n",
    "                         ha=\"center\", va=\"bottom\" if height > 0 else \"top\", fontsize=10, color=\"black\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Год\")\n",
    "    axes[1].set_ylabel(\"Темпы прироста (%)\")\n",
    "    axes[1].set_title(f\"Темпы прироста показателя по годам{region_str}\")\n",
    "    axes[1].axhline(0, color=\"gray\", linestyle=\"dashed\")  # Горизонтальная линия на 0%\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def analyze_indicator_interactive(df):\n",
    "    \"\"\"\n",
    "    Интерактивная версия функции analyze_indicator с выбором региона и показателя.\n",
    "    \"\"\"\n",
    "    df = ravel_domen_dict(df)  # Преобразование данных\n",
    "\n",
    "    # Виджет для выбора региона\n",
    "    region_widget = widgets.Dropdown(\n",
    "        options=[None] + list(df[\"object_name\"].unique()),  # None = все регионы\n",
    "        value=None,\n",
    "        description=\"Регион:\"\n",
    "    )\n",
    "\n",
    "    # Виджет для выбора метода агрегирования\n",
    "    agg_widget = widgets.RadioButtons(\n",
    "        options=[\"mean\", \"median\"],\n",
    "        value=\"mean\",\n",
    "        description=\"Агрегация:\"\n",
    "    )\n",
    "\n",
    "    # Виджет для выбора показателя (обновляется динамически)\n",
    "    indicator_widget = widgets.Dropdown(\n",
    "        options=df.columns[3:], \n",
    "        description=\"Показатель:\"\n",
    "    )\n",
    "\n",
    "    # Функция обработки\n",
    "    def process(region, agg_func, indicator):\n",
    "        df_filtered = df[df[\"object_name\"] == region] if region else df\n",
    "        \n",
    "        # Агрегация данных\n",
    "        if agg_func == \"mean\":\n",
    "            df_grouped = df_filtered.groupby(\"year\")[indicator].mean()\n",
    "        else:\n",
    "            df_grouped = df_filtered.groupby(\"year\")[indicator].median()\n",
    "        \n",
    "        # Стандартное отклонение\n",
    "        df_std = df_filtered.groupby(\"year\")[indicator].std()\n",
    "\n",
    "        # Линейная регрессия\n",
    "        years = df_grouped.index.values\n",
    "        y_values = df_grouped.values\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(years, y_values)\n",
    "        \n",
    "        trend = \"Стационарный ➖\"\n",
    "        if p_value < 0.05:\n",
    "            if slope > 0:\n",
    "                trend = \"Восходящий 📈\"\n",
    "            elif slope < 0:\n",
    "                trend = \"Нисходящий 📉\"\n",
    "\n",
    "        print(f\"\\n📊 Тренд показателя '{indicator}' ({region if region else 'по всем регионам'}): {trend}\")\n",
    "\n",
    "        # Темпы роста\n",
    "        df_pct_change = df_grouped.pct_change() * 100\n",
    "\n",
    "        # Визуализация\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "        # --- График динамики ---\n",
    "        axes[0].plot(df_grouped.index, df_grouped.values, marker=\"o\", label=\"Динамика\", color=\"b\")\n",
    "        axes[0].plot(years, intercept + slope * years, linestyle=\"dashed\", color=\"red\", label=\"Тренд\")\n",
    "        axes[0].fill_between(df_grouped.index, df_grouped - df_std, df_grouped + df_std, color=\"gray\", alpha=0.2)\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # --- График темпов роста ---\n",
    "        colors = [\"green\" if val >= 0 else \"red\" for val in df_pct_change.values]\n",
    "        bars = axes[1].bar(df_pct_change.index, df_pct_change.values, color=colors, alpha=0.7)\n",
    "\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if not np.isnan(height):\n",
    "                axes[1].text(bar.get_x() + bar.get_width()/2, height, f\"{height:.1f}%\", \n",
    "                             ha=\"center\", va=\"bottom\" if height > 0 else \"top\", fontsize=10)\n",
    "\n",
    "        axes[1].axhline(0, color=\"gray\", linestyle=\"dashed\")\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Создание интерактивного интерфейса\n",
    "    interactive_plot = interactive(process, \n",
    "                                   region=region_widget, \n",
    "                                   agg_func=agg_widget, \n",
    "                                   indicator=indicator_widget)\n",
    "    \n",
    "    display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b70f66b3-57bf-48b7-bb11-9b0c655c4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year',\n",
    "]\n",
    "\n",
    "stimulants = [\n",
    "    'Коэффициенты естественного прироста населения на 1000 человек населения (ND)',\n",
    "    'Суммарный коэффициент рождаемости (число детей на 1 женщину)',\n",
    "    # 'Ожидаемая продолжительность жизни при рождении: Все население (число лет)',\n",
    "    'Ожидаемая продолжительность жизни при рождении: Женщины (число лет)',\n",
    "    'Ожидаемая продолжительность жизни при рождении: Мужчины (число лет)',\n",
    "    'Удельный вес городского населения в общей численности населения (оценка на конец года, в процентах)',\n",
    "]\n",
    "\n",
    "destimulants = [\n",
    "    'Коэффициенты демографической нагрузки: Всего (оценка на конец года, на 1000 человек трудоспособного возраста приходится лиц нетрудоспособных возрастов)',\n",
    "    'Смертность населения в трудоспособном возрасте (число умерших на 100 000 человек соответствующего возраста)',\n",
    "    'Соотношение браков и разводов (на 1000 браков приходится разводов)',\n",
    "    'Коэффициенты младенческой смертности (число детей, умерших в возрасте до 1 года, на 1000 родившихся живыми)',\n",
    "    'Общие коэффициенты смертности (число умерших на 1000 человек населения)',\n",
    "]\n",
    "\n",
    "others = [\n",
    "    \n",
    "]\n",
    "\n",
    "# нейтральные добавляются как есть\n",
    "population = {year : Население[year][neutral].copy() for year in Население.keys()}\n",
    "\n",
    "#########################\n",
    "clear_population = {year : Население[year][neutral].copy() for year in Население.keys()}\n",
    "for year, data in clear_population.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Население[year][stim]\n",
    "for year, data in clear_population.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = Население[year][destim]\n",
    "##########################\n",
    "\n",
    "# стимулянты добавляются как есть\n",
    "for year, data in population.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Население[year][stim]\n",
    "\n",
    "# дестимулянты инвертируется\n",
    "for year, data in population.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -Население[year][destim]\n",
    "\n",
    "# другие пока не учитываются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b7bee06-6c06-4948-9010-b55e06fb0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "stimulants = [\n",
    "    'Валовой коэффициент охвата дошкольным образованием (на конец года, в процентах от численности детей в возрасте 1‒6 лет)',\n",
    "    'Выпуск бакалавров, специалистов, магистров (тысяч человек)',\n",
    "    # 'Выпуск квалифицированных рабочих и служащих (тысяч человек)',\n",
    "    'Выпуск обучающихся организациями, осуществляющих образовательную деятельность по образовательным программам начального, основного и среднего общего образования: Выпуск обучающихся с аттестатом о среднем общем образовании (тысяч человек)',\n",
    "    'Выпуск обучающихся организациями, осуществляющих образовательную деятельность по образовательным программам начального, основного и среднего общего образования: Выпуск обучающихся с аттестатом об основном общем образовании (тысяч человек)',\n",
    "    # 'Выпуск специалистов среднего звена (тысяч человек)',\n",
    "    # 'Обеспеченность детей дошкольного возраста местами в организациях, осуществляющих образовательную деятельность по образовательным программам дошкольного образования, присмотр и уход за детьми (на конец года, приходится мест на 1000 детей)',\n",
    "    'Прием на обучение по программам бакалавриата, специалитета, магистратуры (тысяч человек)',\n",
    "    # 'Прием на обучение по программам подготовки квалифицированных рабочих, служащих (тысяч человек)',\n",
    "    'Прием на обучение по программам подготовки специалистов среднего звена (тысяч человек)',\n",
    "    'Численность аспирантов (на конец года, человек)',\n",
    "    # 'Численность воспитанников организаций, осуществляющих образовательную деятельность по образовательным программам дошкольного образования, присмотр и уход за детьми (на конец года, тысяч человек)',\n",
    "    'Численность докторантов (на конец года, человек)',\n",
    "    'Численность обучающихся организаций, осуществляющих образовательную деятельность по образовательным программам начального, основного и среднего общего образования (на начало учебного года, тысяч человек)',\n",
    "    # 'Численность студентов, обучающихся по программам бакалавриата, специалитета, магистратуры (на начало учебного года, тысяч человек)',\n",
    "    # 'Численность студентов, обучающихся по программам бакалавриата, специалитета, магистратуры на 10 000 человек населения (на начало учебного года, человек)',\n",
    "    'Численность студентов, обучающихся по программам подготовки квалифицированных рабочих, служащих (на конец года,тысяч человек)',\n",
    "    'Численность студентов, обучающихся по программам подготовки специалистов среднего звена (на начало учебного года, тысяч человек)'\n",
    "]\n",
    "\n",
    "destimulants = [\n",
    "    'Удельный вес обучающихся во вторую и третью смены в организациях, осуществляющих образовательную деятельность по образовательным программам начального, основного и среднего общего образования (на начало учебного года, в процентах от общей численности обучающихся)'\n",
    "]\n",
    "\n",
    "others = [\n",
    "    # соотношение приема и выпуска\n",
    "]\n",
    "\n",
    "# нейтральные добавляются как есть\n",
    "education = {year : Образование[year][neutral].copy() for year in Образование.keys()}\n",
    "\n",
    "#########################\n",
    "clear_education = {year : Образование[year][neutral].copy() for year in Образование.keys()}\n",
    "for year, data in clear_education.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Образование[year][stim]\n",
    "for year, data in clear_education.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = Образование[year][destim]\n",
    "##########################\n",
    "\n",
    "# стимулянты добавляются как есть\n",
    "for year, data in education.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Образование[year][stim]\n",
    "    \n",
    "    \n",
    "\n",
    "# дестимулянты инвертируется\n",
    "for year, data in education.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -Образование[year][destim]\n",
    "\n",
    "# другие пока не учитываются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99142a35-9cdb-4293-8424-8156ac2ec829",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "# Стимулянты — показатели, которые должны увеличиваться для улучшения ситуации\n",
    "stimulants = [\n",
    "    'Изменение среднегодовой численности занятых (в процентах к предыдущему году)',\n",
    "    'Нагрузка незанятого населения, состоящего на регистрационном учете в органах службы занятости населения, в расчете на одну заявленную вакансию (на конец года, человек)',\n",
    "    'Потребность в работниках, заявленная работодателями в органы службы занятости населения (на конец года, человек)',\n",
    "    'Среднегодовая численность занятых (тысяч человек)',\n",
    "    'Уровень занятости населения (по данным выборочных обследований рабочей силы, в процентах)',\n",
    "    'Уровень занятости населения в трудоспособном возрасте (по данным выборочных обследований рабочей силы, в процентах)',\n",
    "    'Уровень участия в составе рабочей силы (по данным выборочных обследований рабочей силы, в процентах)',\n",
    "    'Численность рабочей силы (по данным выборочных обследований рабочей силы, тысяч человек)'\n",
    "]\n",
    "\n",
    "# Дестимулянты — показатели, которые должны уменьшаться для улучшения ситуации\n",
    "destimulants = [\n",
    "    'Уровень безработицы: Уровень безработицы (по данным выборочных обследований рабочей силы, в процентах)',\n",
    "    'Уровень безработицы: Уровень безработицы в трудоспособном возрасте (по данным выборочных обследований рабочей силы, в процентах)',\n",
    "    'Уровень безработицы: Уровень зарегистрированной безработицы (на конец года, в процентах)',\n",
    "    'Численность безработных (по данным выборочных обследований рабочей силы, тысяч человек)',\n",
    "    'Численность зарегистрированных безработных (на конец года, тысяч человек)',\n",
    "    'Численность незанятых граждан, состоящих на учете в органах службы занятости населения в целях поиска подходящей работы (на конец года, тысяч человек)'\n",
    "]\n",
    "\n",
    "others = [\n",
    "    # Здесь можно добавить другие переменные, если нужно\n",
    "]\n",
    "\n",
    "# Нейтральные данные добавляются как есть\n",
    "labor = {year: Труд[year][neutral].copy() for year in Труд.keys()}\n",
    "\n",
    "#########################\n",
    "clear_labor = {year: Труд[year][neutral].copy() for year in Труд.keys()}\n",
    "for year, data in clear_labor.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Труд[year][stim]\n",
    "for year, data in clear_labor.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = Труд[year][destim]\n",
    "##########################\n",
    "\n",
    "# Стимулянты добавляются как есть\n",
    "for year, data in labor.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = Труд[year][stim]\n",
    "    \n",
    "# Дестимулянты инвертируются\n",
    "for year, data in labor.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -Труд[year][destim]\n",
    "\n",
    "# Другие переменные пока не учитываются\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6ad656b-74a4-4a31-a644-27b759286e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только регионы\n",
    "population = {year : population[year][population[year]['object_level'] == 'регион'] for year in population.keys()}\n",
    "clear_population = {year : clear_population[year][clear_population[year]['object_level'] == 'регион'] for year in clear_population.keys()}\n",
    "\n",
    "education = {year : education[year][education[year]['object_level'] == 'регион'] for year in education.keys()}\n",
    "clear_education = {year : clear_education[year][clear_education[year]['object_level'] == 'регион'] for year in clear_education.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dd9624e-ef09-443d-994f-05a8a6f0fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in population.items():\n",
    "    population[year] = drop_missing_values(df, population[list(population.keys())[0]].columns)\n",
    "for year, df in clear_population.items():\n",
    "    clear_population[year] = drop_missing_values(df, clear_population[list(clear_population.keys())[0]].columns)\n",
    "\n",
    "\n",
    "for year, df in education.items():\n",
    "    education[year] = drop_missing_values(df, education[list(education.keys())[0]].columns)\n",
    "for year, df in clear_education.items():\n",
    "    clear_education[year] = drop_missing_values(df, clear_education[list(clear_education.keys())[0]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de9659de-d3b6-48a8-8fbd-2af24a061a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_hdf5(data: dict[int, pd.DataFrame], filename: str):\n",
    "#     with pd.HDFStore(filename, mode=\"w\") as store:\n",
    "#         for year, df in data.items():\n",
    "#             store.put(f\"year_{year}\", df)\n",
    "\n",
    "# def load_hdf5(filename: str) -> dict[int, pd.DataFrame]:\n",
    "#     data = {}\n",
    "#     with pd.HDFStore(filename, mode=\"r\") as store:\n",
    "#         for key in store.keys():\n",
    "#             year = int(key.split(\"_\")[1])  # Извлекаем год из ключа\n",
    "#             data[year] = store[key]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef82b7f6-955e-443d-a577-91f62f75ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978d399332da4a1db2205c5923c8deea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Домен:', options=('Население', 'Образование'), value='Насе…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domen_mapping = {\n",
    "    \"Население\": (\"population\", \"clear_population\"),\n",
    "    \"Образование\": (\"education\", \"clear_education\"),\n",
    "}\n",
    "\n",
    "# Виджет для выбора домена\n",
    "domen_widget = widgets.Dropdown(\n",
    "    options=domen_mapping.keys(),\n",
    "    description='Домен:'\n",
    ")\n",
    "\n",
    "# Виджеты для выбора параметров\n",
    "region_widget = widgets.Dropdown(\n",
    "    options=[],  # Будет заполняться при выборе домена\n",
    "    description='Регион:'\n",
    ")\n",
    "\n",
    "method_calculation_widget = widgets.Dropdown(\n",
    "    options = ['PCA', 'Обратная дисперсия', 'Равные веса'],\n",
    "    value='PCA',  # Значение по умолчанию - PCA\n",
    "    description='Метод расчета:'\n",
    ")\n",
    "\n",
    "base_year_widget = widgets.IntSlider(\n",
    "    value=2010,\n",
    "    min=2000,\n",
    "    max=2022,\n",
    "    step=1,\n",
    "    description='Базовый год:'\n",
    ")\n",
    "\n",
    "index_share_widget = widgets.FloatSlider(\n",
    "    value=0.9,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Alpha:'\n",
    ")\n",
    "\n",
    "# Кнопки управления\n",
    "load_domen_button = widgets.Button(description=\"Загрузить Домен\", button_style='primary')\n",
    "interactive_analysis_button = widgets.Button(description=\"Интерактивный Анализ\", button_style='info')\n",
    "update_button = widgets.Button(description=\"Обновить данные\", button_style='success')\n",
    "show_table_button = widgets.Button(description=\"Показать таблицу\", button_style='success')\n",
    "\n",
    "# Поля вывода\n",
    "output_domen = widgets.Output()\n",
    "output_interactive = widgets.Output()\n",
    "output_main = widgets.Output()\n",
    "output_table = widgets.Output()\n",
    "\n",
    "# Глобальные переменные\n",
    "domen = None\n",
    "clear_domen = None\n",
    "domen_name = \"\"\n",
    "region_name = \"\"\n",
    "method_calculation = 1\n",
    "\n",
    "# Функция выбора домена\n",
    "def load_domen(_=None):\n",
    "    global domen, clear_domen, domen_name, region_name\n",
    "    domen_key = domen_widget.value\n",
    "    domen_var, clear_domen_var = domen_mapping[domen_key]  # Получаем переменные\n",
    "\n",
    "    # Устанавливаем глобальные переменные\n",
    "    domen = globals()[domen_var]\n",
    "    clear_domen = globals()[clear_domen_var]\n",
    "    domen_name = domen_key  # Человекочитаемое имя домена\n",
    "\n",
    "    # Обновляем список регионов\n",
    "    region_widget.options = domen[list(domen.keys())[0]]['object_name'].unique()\n",
    "\n",
    "    output_domen.clear_output()\n",
    "    with output_domen:\n",
    "        print(f\"Выбран домен: {domen_name}\")\n",
    "\n",
    "load_domen_button.on_click(load_domen)\n",
    "\n",
    "# Функция для интерактивного анализа\n",
    "def interactive_analysis(_=None):\n",
    "    global clear_domen\n",
    "    output_interactive.clear_output()\n",
    "    with output_interactive:\n",
    "        analyze_indicator_interactive(clear_domen)\n",
    "\n",
    "interactive_analysis_button.on_click(interactive_analysis)\n",
    "\n",
    "# Основная обработка данных\n",
    "def process_data(_=None):\n",
    "    global domen, clear_domen, domen_name, region_name, method_calculation\n",
    "\n",
    "    if domen is None:\n",
    "        return\n",
    "    region_name = region_widget.value\n",
    "    base_year = base_year_widget.value\n",
    "    index_share = index_share_widget.value\n",
    "    calculation_method = {'PCA' : 1, 'Обратная дисперсия' : 2, 'Равные веса' : 3}\n",
    "    method_calculation = calculation_method[method_calculation_widget.value]\n",
    "\n",
    "    output_main.clear_output()\n",
    "\n",
    "    with output_main:\n",
    "        print(f\"Обновление данных для региона: {region_name}, базовый год: {base_year}, индекс: {index_share}\")\n",
    "\n",
    "        # Фильтрация данных по региону\n",
    "        domen_filtered = {year: domen[year][domen[year]['object_level'] == 'регион'] for year in domen.keys()}\n",
    "\n",
    "        # Удаление пропусков\n",
    "        for year, df in domen_filtered.items():\n",
    "            domen_filtered[year] = drop_missing_values(df, domen_filtered[list(domen_filtered.keys())[0]].columns)\n",
    "\n",
    "        # Нормализация по текущему году и базовому году\n",
    "        domen_norm_by_current = normalized_dict_by_minmax(domen_filtered)\n",
    "        domen_norm_by_base = normalized_dict_by_minmax_by_base_year(domen_filtered, base_year)\n",
    "\n",
    "        # Расчет индексов и весов\n",
    "        domen_indexes_by_base, weights_by_base = calculate_index_with_weights(domen_norm_by_base, method_calculation)\n",
    "        domen_indexes_by_current, weights_by_current = calculate_index_with_weights(domen_norm_by_current, method_calculation)\n",
    "\n",
    "        # Финальный индекс\n",
    "        domen_final = combine_indices(domen_indexes_by_base, domen_indexes_by_current, index_share)\n",
    "\n",
    "        # Построение графиков\n",
    "        plot_index_trends_multi(domen_indexes_by_base, domen_indexes_by_current, domen_final, region_name, domen_name)\n",
    "        plot_index_trends_with_similar(domen_indexes_by_base, domen_indexes_by_current, domen_final, region_name, domen_name, 3)\n",
    "        plot_top_successful_regions_dynamic(domen_final, domen_name, 15, 0.1)\n",
    "        plot_bottom_successful_regions_dynamic(domen_final, domen_name, 15, 0.1)\n",
    "\n",
    "        # Оценка влияния компонентов\n",
    "        domen_norm_base_weighted = {year: count_impact_per_component(domen_norm_by_base[year], weights_by_base) for year in domen_norm_by_base.keys()}\n",
    "        domen_norm_current_weighted = {year: count_impact_per_component(domen_norm_by_current[year], weights_by_current) for year in domen_norm_by_current.keys()}\n",
    "        global importances_of_domen\n",
    "        importances_of_domen = combine_for_weights_and_importances(domen_norm_base_weighted, domen_norm_current_weighted, index_share)\n",
    "\n",
    "update_button.on_click(process_data)\n",
    "\n",
    "year_widget = widgets.IntSlider(\n",
    "    value=2000,\n",
    "    min=2000,\n",
    "    max=2022,\n",
    "    step=1,\n",
    "    description='Год:'\n",
    ")\n",
    "\n",
    "def show_table(_=None):\n",
    "    # Очищаем вывод графиков\n",
    "    output_main.clear_output()\n",
    "\n",
    "    output_table.clear_output()\n",
    "    with output_table:\n",
    "        selected_year = year_widget.value  # Получаем выбранный год\n",
    "        print(f\"Индекс региона: {region_widget.value}, Год: {selected_year}\")  # Выводим индекс региона и выбранный год\n",
    "        df_importances = rank_importances(clear_domen, domen, importances_of_domen, region_widget.value, selected_year)\n",
    "        display(df_importances)\n",
    "\n",
    "show_table_button.on_click(show_table)\n",
    "\n",
    "clear_screen_button = widgets.Button(description=\"Очистить экран\", button_style='danger')\n",
    "\n",
    "# Функция очистки экрана\n",
    "def clear_screen(_=None):\n",
    "    # Очищаем все области вывода\n",
    "    output_domen.clear_output()\n",
    "    output_interactive.clear_output()\n",
    "    output_main.clear_output()\n",
    "    output_table.clear_output()\n",
    "\n",
    "clear_screen_button.on_click(clear_screen)\n",
    "\n",
    "# Отображение интерфейса с кнопкой очистки экрана\n",
    "display(VBox([\n",
    "    HBox([domen_widget, load_domen_button]),\n",
    "    output_domen,\n",
    "    interactive_analysis_button,\n",
    "    output_interactive,\n",
    "    HBox([region_widget, base_year_widget, index_share_widget]),\n",
    "    HBox([update_button, method_calculation_widget]),\n",
    "    show_table_button,\n",
    "    year_widget,  # Новый виджет для выбора года\n",
    "    output_main,\n",
    "    output_table,\n",
    "    clear_screen_button  # Добавляем кнопку очистки экрана\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d2699-bd4c-4a8a-aadc-e238d2c1b36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f95e99-efb4-45c0-9d0b-8bdc6e0289dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203d6f8-b596-453e-b664-824b2c057c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939744e-ab03-4bde-a839-f84afd826cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
