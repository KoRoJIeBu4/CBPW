{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eed5ca0-1375-412e-8393-3e33ca8e1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import mpld3\n",
    "import os\n",
    "import webbrowser\n",
    "import matplotlib\n",
    "import mplcursors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "import networkx as nx\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pychow import chow_test\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "import networkx as nx\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pychow import chow_test\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan, het_goldfeldquandt, het_arch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, VBox, HBox\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab00618-150a-4b3c-bff8-ff1a355349e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_01_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3543c8e4-22a6-4896-bff6-874b79cfddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['indicator_name'] != \"–°–º–µ—Ä—Ç–Ω–æ—Å—Ç—å –Ω–∞—Å–µ–ª–µ–Ω–∏—è (–±–µ–∑ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç–∏ –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö –ø—Ä–∏—á–∏–Ω)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a12f0dc-da8f-4810-98ef-c6c431fd66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    df1 = df1[['indicator_name', 'object_name', 'object_level', 'year', 'indicator_value', 'indicator_unit']]\n",
    "    assert(all([df1['year'].value_counts().values[i] == len(df1['object_name'].unique()) for i in range(len(df1['year'].value_counts().values))]))\n",
    "    assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1802c4c-f396-4486-81a0-de48af27b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b01adf6-0beb-4877-bd98-c3eff0e84de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—Å–µ –ø—Ä–æ–ø—É—Å–∫–∏ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1adbcee0-3f9b-46cf-bcd9-a75b4ffbfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ–¥–∞\n",
    "–ù–∞—Å–µ–ª–µ–Ω–∏–µ = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec6d041-d463-40fa-91a2-9110ae45d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in –ù–∞—Å–µ–ª–µ–Ω–∏–µ.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # —Å–æ–±—Å–≤—Ç–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –±—ã–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã \n",
    "    assert(len(new_df) == 96)\n",
    "    –ù–∞—Å–µ–ª–µ–Ω–∏–µ[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in –ù–∞—Å–µ–ª–µ–Ω–∏–µ.keys():\n",
    "    total.update(set(–ù–∞—Å–µ–ª–µ–Ω–∏–µ[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af393c8d-43c7-4448-9e82-71f652c67fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_02_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cacc86d7-f58e-484f-9313-2c6313b6cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_cols = np.array([k for k, v in df['indicator_name'].value_counts().items() if v == 2208])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7074fe4-ae66-42be-aa7e-e31985530935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['indicator_name'].isin(needed_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "612ceb2f-389f-4582-b678-6d4325ee6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    df1 = df1[['indicator_name', 'object_name', 'object_level', 'year', 'indicator_value', 'indicator_unit']]\n",
    "    assert(all([df1['year'].value_counts().values[i] == len(df1['object_name'].unique()) for i in range(len(df1['year'].value_counts().values))]))\n",
    "    assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "    dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6986959a-f5ba-4ecc-bb84-b73a3402f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb2fe09-8fe8-41f2-b5c0-f92f50c9ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—Å–µ –ø—Ä–æ–ø—É—Å–∫–∏ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba119cf-d84e-45cd-b49a-b24c8a82ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ–¥–∞\n",
    "–¢—Ä—É–¥ = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abaf5f60-4155-4eab-a523-2de7efe85129",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in –¢—Ä—É–¥.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # —Å–æ–±—Å–≤—Ç–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –±—ã–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã \n",
    "    assert(len(new_df) == 96)\n",
    "    –¢—Ä—É–¥[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in –¢—Ä—É–¥.keys():\n",
    "    total.update(set(–¢—Ä—É–¥[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ec6909d-6168-4fa2-a4c1-57a8dae03133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_04_socio_economic_102_v20240607.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d4244e4-1d68-4747-a6c4-7b55224e4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–ª–µ–Ω–≤–∞–Ω—Ç–Ω—ã–µ –≤ 2000 –≥–æ–¥—É\n",
    "needed = df[df['year'] == 2000]['indicator_name'].unique()\n",
    "df = df[df['indicator_name'].isin(needed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e8e58fa-491d-4a73-baa5-c66fa1df619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—Å–µ –ø—Ä–æ–ø—É—Å–∫–∏ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ np.nan\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -99999999, np.nan)\n",
    "df['indicator_value'] = df['indicator_value'].where(df['indicator_value'] != -77777777, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb7cc5d-c358-4cae-87a2-eec6da3ec74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for name in df['indicator_name'].unique():\n",
    "    df1 = df[df['indicator_name'] == name]\n",
    "    if (len(df1['year'].unique()) == 23):\n",
    "        df1 = df1[['indicator_name', 'object_name', 'year', 'indicator_value', 'indicator_unit']]\n",
    "        df1['indicator_value'] = df1['indicator_value'].where(df1['indicator_value'] >= 0, np.nan)\n",
    "        assert(sorted(df1['year'].unique()) == [i for i in range(2000, 2023, 1)])\n",
    "        assert(len(df1['indicator_unit'].unique()) == 1)\n",
    "        dfs.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc05ddb2-8a6f-48e3-b6b0-4dfd09291c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ–¥–∞\n",
    "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ = {year : None for year in df['year'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d8c2a23-341c-4e3d-b474-1b25fda8d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.keys():\n",
    "    current_df = df[df['year'] == key].copy()\n",
    "    current_df.loc[:,'feature_name'] = current_df['indicator_name'] + ' (' + current_df['indicator_unit'] + ')'\n",
    "\n",
    "    # —Å–æ–±—Å–≤—Ç–µ–Ω–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['object_name'] = current_df['object_name'].unique()\n",
    "    new_df['object_level'] = pd.merge(left=new_df, right=current_df, on='object_name', how='right')['object_level']\n",
    "    new_df['year'] = key\n",
    "    for feature_name in sorted(current_df['feature_name'].unique()):\n",
    "        new_df[feature_name] = pd.merge(left=new_df, right=current_df[current_df['feature_name'] == feature_name], on='object_name', how='right')['indicator_value']\n",
    "\n",
    "    # –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –±—ã–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã \n",
    "    assert(len(new_df) == 96)\n",
    "    –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[key] = new_df\n",
    "\n",
    "total = set()\n",
    "for key in –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.keys():\n",
    "    total.update(set(–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[key].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c360c68-5c8f-4b25-bbf4-564a97b87d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—ã–∫–∏–¥—ã–≤–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "def drop_missing_values(df, reference_columns):\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned = df_cleaned[reference_columns]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "def normalized_dict_by_minmax(dict_of_years: dict[int, pd.DataFrame]):\n",
    "    neutral = (\n",
    "        'object_name',\n",
    "        'object_level',\n",
    "        'year'\n",
    "    )\n",
    "\n",
    "    normilized_dict = {}\n",
    "    for year in dict_of_years.keys():\n",
    "        normilized_dict[year] = dict_of_years[year].copy()\n",
    "        for category in normilized_dict[year].columns:\n",
    "            if category in neutral:\n",
    "                continue\n",
    "            normilized_dict[year][category] = (normilized_dict[year][category] - normilized_dict[year][category].min()) / (normilized_dict[year][category].max() - normilized_dict[year][category].min())\n",
    "    return normilized_dict\n",
    "\n",
    "def normalized_dict_by_minmax_by_base_year(dict_of_years: dict[int, pd.DataFrame], base_year=2010):\n",
    "    min_values_by_features = {}\n",
    "    max_values_by_features = {}\n",
    "    neutral = (\n",
    "        'object_name',\n",
    "        'object_level',\n",
    "        'year'\n",
    "    )\n",
    "\n",
    "    for category in dict_of_years[base_year].columns:\n",
    "        if category in neutral:\n",
    "            continue\n",
    "        min_values_by_features[category] = dict_of_years[base_year][category].min()\n",
    "        max_values_by_features[category] = dict_of_years[base_year][category].max()\n",
    "\n",
    "    normilized_dict = {}\n",
    "    for year in dict_of_years.keys():\n",
    "        normilized_dict[year] = dict_of_years[year].copy()\n",
    "        for category in normilized_dict[year].columns:\n",
    "            if category in neutral:\n",
    "                continue\n",
    "            normilized_dict[year][category] = (normilized_dict[year][category] - min_values_by_features[category]) / (max_values_by_features[category] - min_values_by_features[category])\n",
    "    return normilized_dict\n",
    "\n",
    "def calculate_index_with_weights(dict_of_dataframes, way_of_calculating=1):\n",
    "    '''\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç –∏–Ω–¥–µ–∫—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    dict_of_dataframes (dict): –°–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á–∏ - –≥–æ–¥—ã, –∞ –∑–Ω–∞—á–µ–Ω–∏—è - DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏.\n",
    "    way_of_calculating (int): –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤:\n",
    "        1 - PCA (–∞–Ω–∞–ª–∏–∑ –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç);\n",
    "        2 - –û–±—Ä–∞—Ç–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è;\n",
    "        3 - –†–∞–≤–Ω—ã–µ –≤–µ—Å–∞.\n",
    "\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    tuple: –ö–æ—Ä—Ç–µ–∂, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π DataFrame —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –ø–æ –≥–æ–¥–∞–º –∏ –º–∞—Å—Å–∏–≤ –≤–µ—Å–æ–≤.\n",
    "    '''\n",
    "    \n",
    "    indexed_data = {}\n",
    "    combined_data = pd.concat(dict_of_dataframes.values())\n",
    "    numerical_columns = combined_data.drop(columns=['object_name', 'object_level', 'year'])\n",
    "\n",
    "    if way_of_calculating == 1:  # PCA\n",
    "        pca = PCA(n_components=1)\n",
    "        pca.fit(numerical_columns)\n",
    "        weights = np.abs(pca.components_[0])\n",
    "        weights /= weights.sum()\n",
    "    \n",
    "    elif way_of_calculating == 2:  # –û–±—Ä–∞—Ç–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è\n",
    "        variances = numerical_columns.var()\n",
    "        weights = 1 / variances\n",
    "        weights /= weights.sum()\n",
    "    \n",
    "    else:  # –†–∞–≤–Ω—ã–µ –≤–µ—Å–∞\n",
    "        num_columns = numerical_columns.shape[1]\n",
    "        weights = np.ones(num_columns) / num_columns\n",
    "    \n",
    "    for year, df in dict_of_dataframes.items():\n",
    "        numerical_columns = df.drop(columns=['object_name', 'object_level', 'year'])\n",
    "        weighted_mean = (numerical_columns * weights).sum(axis=1)\n",
    "        df['index'] = weighted_mean\n",
    "        indexed_data[year] = df[['object_name', 'index']]\n",
    "    \n",
    "    combined_index = pd.DataFrame()\n",
    "    for year, df in indexed_data.items():\n",
    "        df = df.set_index('object_name')['index']\n",
    "        combined_index[year] = df\n",
    "\n",
    "    return combined_index, weights\n",
    "\n",
    "def combine_indices(df1, df2, alpha):\n",
    "    if not df1.shape == df2.shape:\n",
    "        raise ValueError(\"–î–∞—Ç–∞—Ñ—Ä–µ–π–º—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (—Ä–∞–∑–º–µ—Ä—ã –∏ –∏–Ω–¥–µ–∫—Å—ã).\")\n",
    "    if not (df1.index.equals(df2.index) and df1.columns.equals(df2.columns)):\n",
    "        raise ValueError(\"–î–∞—Ç–∞—Ñ—Ä–µ–π–º—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –∏ —Å—Ç–æ–ª–±—Ü—ã.\")\n",
    "\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"Alpha –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ—Ç 0 –¥–æ 1.\")\n",
    "\n",
    "    combined_df = alpha * df1 + (1 - alpha) * df2\n",
    "    return combined_df\n",
    "\n",
    "def plot_index_trends_multi(dfs_by_base, dfs_by_current, dfs_final, region, domen):\n",
    "    if not (dfs_by_base.index.equals(dfs_by_current.index) and dfs_by_current.index.equals(dfs_final.index)):\n",
    "        raise ValueError(\"–ò–Ω–¥–µ–∫—Å—ã —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å –≤–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö.\")\n",
    "    \n",
    "    region_name = region\n",
    "    base_index = dfs_by_base.loc[region]\n",
    "    current_index = dfs_by_current.loc[region]\n",
    "    final_index = dfs_final.loc[region]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(final_index.index, final_index.values, marker='o', linestyle='-', linewidth=3,\n",
    "             label=\"Final Index\", color='red', alpha=0.9)  # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω–¥–µ–∫—Å\n",
    "    plt.plot(base_index.index, base_index.values, marker='o', linestyle='--', linewidth=2,\n",
    "             label=\"Base Index\", color='blue', alpha=0.5)\n",
    "    plt.plot(current_index.index, current_index.values, marker='o', linestyle=':', linewidth=2,\n",
    "             label=\"Current Index\", color='green', alpha=0.5)\n",
    "    plt.title(f\"{domen}. –î–∏–Ω–∞–º–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ –≥–æ–¥–∞–º –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞: {region_name}\", fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(\"–ì–æ–¥\", fontsize=14)\n",
    "    plt.ylabel(\"–ò–Ω–¥–µ–∫—Å\", fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    for i in range(len(final_index)):\n",
    "        plt.annotate(f\"{final_index.values[i]:.2f}\", \n",
    "                     (final_index.index[i], final_index.values[i]),\n",
    "                     textcoords=\"offset points\", \n",
    "                     xytext=(0,10), \n",
    "                     ha='center', fontsize=10, color='red')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_facecolor('#f9f9f9')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_index_trends_with_similar(dfs_by_base, dfs_by_current, dfs_final, region_name, domen, k=3):\n",
    "    if not (dfs_by_base.index.equals(dfs_by_current.index) and dfs_by_current.index.equals(dfs_final.index)):\n",
    "        raise ValueError(\"–ò–Ω–¥–µ–∫—Å—ã —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å –≤–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö.\")\n",
    "    if region_name not in dfs_final.index:\n",
    "        raise ValueError(f\"–†–µ–≥–∏–æ–Ω '{region_name}' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö.\")\n",
    "    target_vector = dfs_final.loc[region_name].values.reshape(1, -1)\n",
    "    distances = cdist(target_vector, dfs_final.values, metric='euclidean').flatten()\n",
    "    similar_indices = np.argsort(distances)[1:k + 1]\n",
    "    similar_regions = dfs_final.index[similar_indices]\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.gca().set_facecolor('white') \n",
    "    plt.grid(color='lightgrey', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.plot(dfs_final.columns, dfs_final.loc[region_name], \n",
    "             marker='o', linestyle='-', linewidth=3, label=f\"{region_name} (Target)\", \n",
    "             color='orange', alpha=0.9, zorder=5) \n",
    "    \n",
    "    colors = ['#FF6347', '#4682B4', '#32CD32', '#FFD700', '#8A2BE2']\n",
    "    \n",
    "    for i, similar_region in enumerate(similar_regions):\n",
    "        plt.plot(dfs_final.columns, dfs_final.loc[similar_region], \n",
    "                 marker='s', linestyle=':', linewidth=2, label=similar_region,\n",
    "                 color=colors[i % len(colors)], alpha=0.8)\n",
    "\n",
    "        max_value = dfs_final.loc[similar_region].max()\n",
    "        min_value = dfs_final.loc[similar_region].min()\n",
    "        max_index = dfs_final.loc[similar_region].idxmax()\n",
    "        min_index = dfs_final.loc[similar_region].idxmin()\n",
    "        \n",
    "        plt.scatter(max_index, max_value, color=colors[i % len(colors)], s=100, zorder=10, edgecolor='black', marker='o')\n",
    "        plt.scatter(min_index, min_value, color=colors[i % len(colors)], s=100, zorder=10, edgecolor='black', marker='^')\n",
    "\n",
    "    max_value_target = dfs_final.loc[region_name].max()\n",
    "    min_value_target = dfs_final.loc[region_name].min()\n",
    "    max_index_target = dfs_final.loc[region_name].idxmax()\n",
    "    min_index_target = dfs_final.loc[region_name].idxmin()\n",
    "    plt.scatter(max_index_target, max_value_target, color='orange', s=100, zorder=10, edgecolor='black', marker='o', label='–ú–∞–∫—Å–∏–º—É–º')\n",
    "    plt.scatter(min_index_target, min_value_target, color='orange', s=100, zorder=10, edgecolor='black', marker='^', label='–ú–∏–Ω–∏–º—É–º')\n",
    "    plt.title(f\"{domen}. –î–∏–Ω–∞–º–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ '{region_name}' –∏ {k} –ø–æ—Ö–æ–∂–∏—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤\", fontsize=18, fontweight='bold', color='#333')\n",
    "    plt.xlabel(\"–ì–æ–¥\", fontsize=14)\n",
    "    plt.ylabel(\"–ò–Ω–¥–µ–∫—Å\", fontsize=14)\n",
    "    \n",
    "    plt.legend(fontsize=12, loc=\"best\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_successful_regions_dynamic(dfs_final, domen, top_n=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É —Ç–æ–ø-N —Å–∞–º—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤, —É—á–∏—Ç—ã–≤–∞—è —É—Ä–æ–≤–µ–Ω—å –∏–Ω–¥–µ–∫—Å–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥ –∏ –¥–∏–Ω–∞–º–∏–∫—É.\n",
    "    –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "    \n",
    "    Args:\n",
    "        dfs_final (pd.DataFrame): –î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ (–∏–Ω–¥–µ–∫—Å—ã - —Ä–µ–≥–∏–æ–Ω—ã, –∫–æ–ª–æ–Ω–∫–∏ - –≥–æ–¥—ã).\n",
    "        top_n (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
    "        alpha (float): –í–µ—Å –¥–ª—è –¥–∏–Ω–∞–º–∏–∫–∏ (0 <= alpha <= 1). \n",
    "                       –í–µ—Å —É—Ä–æ–≤–Ω—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≥–æ–¥–∞ = 1 - alpha.\n",
    "    \"\"\"\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"–ü–∞—Ä–∞–º–µ—Ç—Ä alpha –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 1.\")\n",
    "    \n",
    "    index_growth = dfs_final.diff(axis=1).mean(axis=1)\n",
    "    last_year = dfs_final.columns[-1]\n",
    "    last_year_index = dfs_final[last_year]\n",
    "    combined_score = alpha * index_growth + (1 - alpha) * last_year_index\n",
    "    top_regions = combined_score.sort_values(ascending=False).head(top_n)\n",
    "    norm = plt.Normalize(min(top_regions), max(top_regions))\n",
    "    cmap = matplotlib.colormaps['coolwarm']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))  # –°–æ–∑–¥–∞–µ–º –æ—Å—å ax\n",
    "    bars = ax.barh(top_regions.sort_values().index, top_regions.sort_values(), color=cmap(norm(top_regions.sort_values())))\n",
    "    \n",
    "    for bar in bars:\n",
    "        bar.set_edgecolor('black')\n",
    "        bar.set_linewidth(1.5) \n",
    "        for i, (region, value) in enumerate(zip(top_regions.sort_values().index, top_regions.sort_values())):\n",
    "            ax.text(value + 0.01, i, f\"({value:.3f})\", va='center', fontsize=12, color='black', weight='bold')\n",
    "    \n",
    "    ax.set_title(f\"{domen}. –¢–æ–ø-{top_n} —Å–∞–º—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏–∫–∏ ({last_year})\", fontsize=16, weight='bold')\n",
    "    ax.set_xlabel(\"–ö—É–º–º—É–ª—è—Ç–∏–≤–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥\", fontsize=14)\n",
    "    ax.set_ylabel(\"–†–µ–≥–∏–æ–Ω—ã\", fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_bottom_successful_regions_dynamic(dfs_final, domen, bottom_n=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    –°—Ç—Ä–æ–∏—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É bottom-N –Ω–∞–∏–º–µ–Ω–µ–µ —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤, —É—á–∏—Ç—ã–≤–∞—è —É—Ä–æ–≤–µ–Ω—å –∏–Ω–¥–µ–∫—Å–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥ –∏ –¥–∏–Ω–∞–º–∏–∫—É.\n",
    "    –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
    "    \n",
    "    Args:\n",
    "        dfs_final (pd.DataFrame): –î–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ (–∏–Ω–¥–µ–∫—Å—ã - —Ä–µ–≥–∏–æ–Ω—ã, –∫–æ–ª–æ–Ω–∫–∏ - –≥–æ–¥—ã).\n",
    "        bottom_n (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∏–º–µ–Ω–µ–µ —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
    "        alpha (float): –í–µ—Å –¥–ª—è –¥–∏–Ω–∞–º–∏–∫–∏ (0 <= alpha <= 1). \n",
    "                       –í–µ—Å —É—Ä–æ–≤–Ω—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≥–æ–¥–∞ = 1 - alpha.\n",
    "    \"\"\"\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"–ü–∞—Ä–∞–º–µ—Ç—Ä alpha –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 1.\")\n",
    "    \n",
    "    index_growth = dfs_final.diff(axis=1).mean(axis=1)\n",
    "    last_year = dfs_final.columns[-1]\n",
    "    last_year_index = dfs_final[last_year]\n",
    "    combined_score = alpha * index_growth + (1 - alpha) * last_year_index\n",
    "    \n",
    "    bottom_regions = combined_score.sort_values(ascending=True).head(bottom_n)\n",
    "    norm = plt.Normalize(min(bottom_regions), max(bottom_regions))\n",
    "    cmap = matplotlib.colormaps['Reds']  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–≤–µ—Ç–æ–≤—É—é —Å—Ö–µ–º—É –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    bars = ax.barh(bottom_regions.sort_values(ascending=False).index, \n",
    "                   bottom_regions.sort_values(ascending=False), \n",
    "                   color=cmap(norm(bottom_regions.sort_values(ascending=False))))\n",
    "    \n",
    "    for bar in bars:\n",
    "        bar.set_edgecolor('black')\n",
    "        bar.set_linewidth(1.5) \n",
    "        for i, (region, value) in enumerate(zip(bottom_regions.sort_values(ascending=False).index, \n",
    "                                                bottom_regions.sort_values(ascending=False))):\n",
    "            ax.text(value + 0.01, i, f\"({value:.3f})\", va='center', fontsize=12, color='black', weight='bold')\n",
    "    \n",
    "    ax.set_title(f\"{domen}. –¢–æ–ø-{bottom_n} –Ω–∞–∏–º–µ–Ω–µ–µ —É—Å–ø–µ—à–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å —É—á–µ—Ç–æ–º –¥–∏–Ω–∞–º–∏–∫–∏ ({last_year})\", \n",
    "                 fontsize=16, weight='bold', color='darkred')\n",
    "    ax.set_xlabel(\"–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥\", fontsize=14)\n",
    "    ax.set_ylabel(\"–†–µ–≥–∏–æ–Ω—ã\", fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mean_weight(weights_by_base, weights_by_current, alpha=0.9):\n",
    "    return weights_by_base * alpha + (1 - alpha) * weights_by_current\n",
    "\n",
    "def count_impact_per_component(df : pd.DataFrame, weights : np.array):\n",
    "    '''\n",
    "    –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–≤–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞:\n",
    "        df : —Ç–µ–∫—É—â–∏–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "        weights : –≤–µ—Å–∞ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    Return:\n",
    "        –£–º–Ω–æ–∂–∞–µ–º –≤–µ—Å–∞ –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    '''\n",
    "    buff_df = df.copy()\n",
    "    buff_df.iloc[:,3:-1] = buff_df.iloc[:,3:-1] * weights \n",
    "    return buff_df\n",
    "\n",
    "def combine_for_weights_and_importances(dfs1, dfs2, index_share):\n",
    "    '''\n",
    "    –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è\n",
    "    –ù—É–∂–Ω–∞, —á—Ç–æ–±—ã –≤—ã—á–∏—Å–ª—è—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –¥–æ–ª—è—Ö\n",
    "    '''\n",
    "    dfs_final = {}\n",
    "    for year in dfs1.keys():\n",
    "        dfs_final[year] = dfs1[year].copy()\n",
    "        dfs_final[year].iloc[:,3:-1] = dfs_final[year].iloc[:,3:-1] * index_share + dfs2[year].iloc[:,3:-1] * (1-index_share)\n",
    "        total_sum = dfs_final[year].iloc[:,3:-1].sum(axis=1)\n",
    "        dfs_final[year] = dfs_final[year].drop('index', axis=1)\n",
    "        for col in dfs_final[year].columns[3:]:\n",
    "            dfs_final[year][col] /= total_sum\n",
    "    return dfs_final\n",
    "\n",
    "def rank_importances(clear_domen, domen, importances_of_domen, region, year):\n",
    "    if isinstance(year, list):\n",
    "        start = year[0]\n",
    "        end = year[1]\n",
    "        df = importances_of_domen[start][importances_of_domen[start]['object_name'] == region].iloc[:,3:].transpose()\n",
    "        df.columns = ['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†']\n",
    "        for year in range(start+1, end+1, 1):\n",
    "            chosen = importances_of_domen[year][importances_of_domen[year]['object_name'] == region].iloc[:,3:].transpose()\n",
    "            chosen.columns = ['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†']\n",
    "            df += chosen\n",
    "        df['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†'] = df['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†'] / (end - start + 1)\n",
    "        df = df.sort_values(by='–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†', ascending=False) \n",
    "        return df\n",
    "    else:   \n",
    "        chosen = importances_of_domen[year][importances_of_domen[year]['object_name'] == region].iloc[:,3:].transpose()\n",
    "        chosen.columns = ['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†']\n",
    "        values = clear_domen[year][clear_domen[year]['object_name'] == region].iloc[:, 3:].transpose()\n",
    "        values.columns = ['–ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è']\n",
    "        chosen = pd.concat([chosen, values], axis=1)\n",
    "        chosen = chosen.sort_values(by='–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†', ascending=False)\n",
    "\n",
    "        category = {'–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ' : [], '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ' : []}\n",
    "        clear = clear_domen[year][clear_domen[year]['object_name'] == region].iloc[:,3:]\n",
    "        modified = domen[year][domen[year]['object_name'] == region].iloc[:,3:]\n",
    "\n",
    "        for col in clear.columns:\n",
    "            if clear[col].values == modified[col].values:\n",
    "                category['–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ'].append(col)\n",
    "            else:\n",
    "                category['–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ'].append(col)\n",
    "        chosen['–¢–∏–ø –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è'] = chosen.index.to_series().apply(\n",
    "            lambda x: '–°—Ç–∏–º—É–ª—è–Ω—Ç' if x in category['–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ'] else '–î–µ—Å—Ç–∏–º—É–ª—è–Ω—Ç'\n",
    "        )\n",
    "\n",
    "        # –≥–∞—Ä–∞–Ω—Ç–∏—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏\n",
    "        total = chosen['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†'].sum()\n",
    "        chosen['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†'] = np.abs(chosen['–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†']) / total\n",
    "        chosen = chosen.sort_values(by='–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ò–†–†', ascending=False)\n",
    "        \n",
    "        return chosen\n",
    "\n",
    "def ravel_domen_final(data):\n",
    "    '''\n",
    "    data: pd.DataFrame\n",
    "    –í—ã—Ç—è–≥–∏–µ–≤–∞–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç–æ–ª–±—Ü–æ–≤: –≥–æ–¥, —Ä–µ–≥–∏–æ–Ω, –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞\n",
    "    '''\n",
    "    data = data.reset_index()\n",
    "    melted_data = data.melt(id_vars=[data.columns[0]], \n",
    "                             var_name='–≥–æ–¥', \n",
    "                             value_name='–∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞')\n",
    "    \n",
    "    melted_data.rename(columns={data.columns[0]: '—Ä–µ–≥–∏–æ–Ω'}, inplace=True)\n",
    "    \n",
    "    return melted_data\n",
    "\n",
    "def ravel_domen_dict(data_dict):\n",
    "    '''\n",
    "    data_dict: dict\n",
    "    –°–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á–∏ - –≥–æ–¥—ã, –∑–Ω–∞—á–µ–Ω–∏—è - DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: object_name, object_level, year –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: –≥–æ–¥, object_name, object_level –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
    "    '''\n",
    "    df_list = []\n",
    "    \n",
    "    for year, df in data_dict.items():\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"DataFrame for year {year} is empty.\")\n",
    "        if not all(col in df.columns for col in ['object_name', 'object_level', 'year']):\n",
    "            raise ValueError(f\"DataFrame for year {year} is missing required columns.\")\n",
    "        \n",
    "        df['year'] = year\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def analyze_indicator(df, agg_func=\"mean\", region=None):\n",
    "    \"\"\"\n",
    "    –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∏–Ω–∞–º–∏–∫—É –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –ø–æ –≥–æ–¥–∞–º, —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω—É.\n",
    "\n",
    "    :param df: Dict[int : pd.DataFrame]\n",
    "    :param agg_func: \"mean\" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∏–ª–∏ \"median\" - –º–µ—Ç–æ–¥ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    :param region: –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ (–∏–ª–∏ None, —á—Ç–æ–±—ã —Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ –≤—Å–µ–º)\n",
    "    \"\"\"\n",
    "    # 1Ô∏è‚É£ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–≥–∏–æ–Ω—É, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω\n",
    "    df = ravel_domen_dict(df)\n",
    "    if region:\n",
    "        df = df[df[\"object_name\"] == region]\n",
    "\n",
    "    # 2Ô∏è‚É£ –í—ã–±–æ—Ä –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è\n",
    "    indicators = df.columns[3:]  # –í—Å–µ —Å—Ç–æ–ª–±—Ü—ã –ø–æ—Å–ª–µ 'year'\n",
    "    print(\"\\n–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\")\n",
    "    for i, col in enumerate(indicators, 1):\n",
    "        print(f\"{i}) {col}\")\n",
    "\n",
    "    choice = int(input(\"\\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è: \")) - 1\n",
    "    indicator = indicators[choice]\n",
    "\n",
    "    # 3Ô∏è‚É£ –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–ø–æ –≥–æ–¥–∞–º)\n",
    "    if agg_func == \"mean\":\n",
    "        df_grouped = df.groupby(\"year\")[indicator].mean()\n",
    "    elif agg_func == \"median\":\n",
    "        df_grouped = df.groupby(\"year\")[indicator].median()\n",
    "    else:\n",
    "        raise ValueError(\"–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ agg_func. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'mean' –∏–ª–∏ 'median'.\")\n",
    "\n",
    "    # 4Ô∏è‚É£ –†–∞—Å—á–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –¥–ª—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞\n",
    "    df_std = df.groupby(\"year\")[indicator].std()\n",
    "\n",
    "    # 5Ô∏è‚É£ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç—Ä–µ–Ω–¥ (–ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)\n",
    "    years = df_grouped.index.values\n",
    "    y_values = df_grouped.values\n",
    "\n",
    "    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(years, y_values)\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –Ω–∞–∫–ª–æ–Ω–∞\n",
    "    if p_value < 0.05:  # –£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ 0.05\n",
    "        trend_slope = slope\n",
    "        if trend_slope > 0:\n",
    "            trend = \"–í–æ—Å—Ö–æ–¥—è—â–∏–π üìà\"\n",
    "        elif trend_slope < 0:\n",
    "            trend = \"–ù–∏—Å—Ö–æ–¥—è—â–∏–π üìâ\"\n",
    "    else:\n",
    "        trend = \"–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π ‚ûñ\"\n",
    "\n",
    "    region_str = f\" ({region})\" if region else \" (–ø–æ –≤—Å–µ–º —Ä–µ–≥–∏–æ–Ω–∞–º)\"\n",
    "    print(f\"\\nüìä –¢—Ä–µ–Ω–¥ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è '{indicator}'{region_str}: {trend}\")\n",
    "\n",
    "    # 6Ô∏è‚É£ –¢–µ–º–ø—ã —Ä–æ—Å—Ç–∞ (% –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞)\n",
    "    df_pct_change = df_grouped.pct_change() * 100\n",
    "\n",
    "    # 7Ô∏è‚É£ –¢–æ–ø-3 –≥–æ–¥–∞ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é\n",
    "    top_years = df_grouped.nlargest(3)\n",
    "    print(\"\\nüèÜ –¢–æ–ø-3 –≥–æ–¥–∞ –ø–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—é:\")\n",
    "    print(top_years)\n",
    "\n",
    "    # üîπ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è üîπ\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # --- –ü–µ—Ä–≤—ã–π –≥—Ä–∞—Ñ–∏–∫: –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è ---\n",
    "    axes[0].plot(df_grouped.index, df_grouped.values, marker=\"o\", label=\"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è\", color=\"b\")\n",
    "    axes[0].plot(years, intercept + slope * years, linestyle=\"dashed\", color=\"red\", label=\"–õ–∏–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞\")\n",
    "    axes[0].fill_between(df_grouped.index, df_grouped - df_std, df_grouped + df_std, color=\"gray\", alpha=0.2)\n",
    "\n",
    "    axes[0].set_xlabel(\"–ì–æ–¥\")\n",
    "    # axes[0].set_title(f\"–î–∏–Ω–∞–º–∏–∫–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è: {indicator}{region_str}\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # --- –í—Ç–æ—Ä–æ–π –≥—Ä–∞—Ñ–∏–∫: –¢–µ–º–ø—ã —Ä–æ—Å—Ç–∞ (—Å—Ç–æ–ª–±–∏–∫–∞–º–∏) ---\n",
    "    colors = [\"green\" if val >= 0 else \"red\" for val in df_pct_change.values]\n",
    "\n",
    "    bars = axes[1].bar(df_pct_change.index, df_pct_change.values, color=colors, alpha=0.7)\n",
    "\n",
    "    # üî¢ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞–¥ —Å—Ç–æ–ª–±—Ü–∞–º–∏\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if not np.isnan(height):  # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã –Ω–µ –ø–∏—Å–∞—Ç—å NaN\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, height, f\"{height:.1f}%\", \n",
    "                         ha=\"center\", va=\"bottom\" if height > 0 else \"top\", fontsize=10, color=\"black\")\n",
    "\n",
    "    axes[1].set_xlabel(\"–ì–æ–¥\")\n",
    "    axes[1].set_ylabel(\"–¢–µ–º–ø—ã –ø—Ä–∏—Ä–æ—Å—Ç–∞ (%)\")\n",
    "    axes[1].set_title(f\"–¢–µ–º–ø—ã –ø—Ä–∏—Ä–æ—Å—Ç–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –ø–æ –≥–æ–¥–∞–º{region_str}\")\n",
    "    axes[1].axhline(0, color=\"gray\", linestyle=\"dashed\")  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è –Ω–∞ 0%\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def analyze_indicator_interactive(df):\n",
    "    \"\"\"\n",
    "    –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ analyze_indicator —Å –≤—ã–±–æ—Ä–æ–º —Ä–µ–≥–∏–æ–Ω–∞ –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è.\n",
    "    \"\"\"\n",
    "    df = ravel_domen_dict(df)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "    # –í–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ä–µ–≥–∏–æ–Ω–∞\n",
    "    region_widget = widgets.Dropdown(\n",
    "        options=[None] + list(df[\"object_name\"].unique()),  # None = –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã\n",
    "        value=None,\n",
    "        description=\"–†–µ–≥–∏–æ–Ω:\"\n",
    "    )\n",
    "\n",
    "    # –í–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "    agg_widget = widgets.RadioButtons(\n",
    "        options=[\"mean\", \"median\"],\n",
    "        value=\"mean\",\n",
    "        description=\"–ê–≥—Ä–µ–≥–∞—Ü–∏—è:\"\n",
    "    )\n",
    "\n",
    "    # –í–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏)\n",
    "    indicator_widget = widgets.Dropdown(\n",
    "        options=df.columns[3:], \n",
    "        description=\"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å:\"\n",
    "    )\n",
    "\n",
    "    # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "    def process(region, agg_func, indicator):\n",
    "        df_filtered = df[df[\"object_name\"] == region] if region else df\n",
    "        \n",
    "        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "        if agg_func == \"mean\":\n",
    "            df_grouped = df_filtered.groupby(\"year\")[indicator].mean()\n",
    "        else:\n",
    "            df_grouped = df_filtered.groupby(\"year\")[indicator].median()\n",
    "        \n",
    "        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ\n",
    "        df_std = df_filtered.groupby(\"year\")[indicator].std()\n",
    "\n",
    "        # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "        years = df_grouped.index.values\n",
    "        y_values = df_grouped.values\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(years, y_values)\n",
    "        \n",
    "        trend = \"–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π ‚ûñ\"\n",
    "        if p_value < 0.05:\n",
    "            if slope > 0:\n",
    "                trend = \"–í–æ—Å—Ö–æ–¥—è—â–∏–π üìà\"\n",
    "            elif slope < 0:\n",
    "                trend = \"–ù–∏—Å—Ö–æ–¥—è—â–∏–π üìâ\"\n",
    "\n",
    "        print(f\"\\nüìä –¢—Ä–µ–Ω–¥ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è '{indicator}' ({region if region else '–ø–æ –≤—Å–µ–º —Ä–µ–≥–∏–æ–Ω–∞–º'}): {trend}\")\n",
    "\n",
    "        # –¢–µ–º–ø—ã —Ä–æ—Å—Ç–∞\n",
    "        df_pct_change = df_grouped.pct_change() * 100\n",
    "\n",
    "        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "        # --- –ì—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏ ---\n",
    "        axes[0].plot(df_grouped.index, df_grouped.values, marker=\"o\", label=\"–î–∏–Ω–∞–º–∏–∫–∞\", color=\"b\")\n",
    "        axes[0].plot(years, intercept + slope * years, linestyle=\"dashed\", color=\"red\", label=\"–¢—Ä–µ–Ω–¥\")\n",
    "        axes[0].fill_between(df_grouped.index, df_grouped - df_std, df_grouped + df_std, color=\"gray\", alpha=0.2)\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "\n",
    "        # --- –ì—Ä–∞—Ñ–∏–∫ —Ç–µ–º–ø–æ–≤ —Ä–æ—Å—Ç–∞ ---\n",
    "        colors = [\"green\" if val >= 0 else \"red\" for val in df_pct_change.values]\n",
    "        bars = axes[1].bar(df_pct_change.index, df_pct_change.values, color=colors, alpha=0.7)\n",
    "\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if not np.isnan(height):\n",
    "                axes[1].text(bar.get_x() + bar.get_width()/2, height, f\"{height:.1f}%\", \n",
    "                             ha=\"center\", va=\"bottom\" if height > 0 else \"top\", fontsize=10)\n",
    "\n",
    "        axes[1].axhline(0, color=\"gray\", linestyle=\"dashed\")\n",
    "        axes[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞\n",
    "    interactive_plot = interactive(process, \n",
    "                                   region=region_widget, \n",
    "                                   agg_func=agg_widget, \n",
    "                                   indicator=indicator_widget)\n",
    "    \n",
    "    display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b70f66b3-57bf-48b7-bb11-9b0c655c4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year',\n",
    "]\n",
    "\n",
    "stimulants = [\n",
    "    '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ—Å—Ç–∞ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –Ω–∞ 1000 —á–µ–ª–æ–≤–µ–∫ –Ω–∞—Å–µ–ª–µ–Ω–∏—è (ND)',\n",
    "    '–°—É–º–º–∞—Ä–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–æ–∂–¥–∞–µ–º–æ—Å—Ç–∏ (—á–∏—Å–ª–æ –¥–µ—Ç–µ–π –Ω–∞ 1 –∂–µ–Ω—â–∏–Ω—É)',\n",
    "    # '–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∂–∏–∑–Ω–∏ –ø—Ä–∏ —Ä–æ–∂–¥–µ–Ω–∏–∏: –í—Å–µ –Ω–∞—Å–µ–ª–µ–Ω–∏–µ (—á–∏—Å–ª–æ –ª–µ—Ç)',\n",
    "    '–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∂–∏–∑–Ω–∏ –ø—Ä–∏ —Ä–æ–∂–¥–µ–Ω–∏–∏: –ñ–µ–Ω—â–∏–Ω—ã (—á–∏—Å–ª–æ –ª–µ—Ç)',\n",
    "    '–û–∂–∏–¥–∞–µ–º–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∂–∏–∑–Ω–∏ –ø—Ä–∏ —Ä–æ–∂–¥–µ–Ω–∏–∏: –ú—É–∂—á–∏–Ω—ã (—á–∏—Å–ª–æ –ª–µ—Ç)',\n",
    "    '–£–¥–µ–ª—å–Ω—ã–π –≤–µ—Å –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –≤ –æ–±—â–µ–π —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è (–æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "]\n",
    "\n",
    "destimulants = [\n",
    "    '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏: –í—Å–µ–≥–æ (–æ—Ü–µ–Ω–∫–∞ –Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, –Ω–∞ 1000 —á–µ–ª–æ–≤–µ–∫ —Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –ª–∏—Ü –Ω–µ—Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω—ã—Ö –≤–æ–∑—Ä–∞—Å—Ç–æ–≤)',\n",
    "    '–°–º–µ—Ä—Ç–Ω–æ—Å—Ç—å –Ω–∞—Å–µ–ª–µ–Ω–∏—è –≤ —Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ–º –≤–æ–∑—Ä–∞—Å—Ç–µ (—á–∏—Å–ª–æ —É–º–µ—Ä—à–∏—Ö –Ω–∞ 100 000 —á–µ–ª–æ–≤–µ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞)',\n",
    "    '–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –±—Ä–∞–∫–æ–≤ –∏ —Ä–∞–∑–≤–æ–¥–æ–≤ (–Ω–∞ 1000 –±—Ä–∞–∫–æ–≤ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è —Ä–∞–∑–≤–æ–¥–æ–≤)',\n",
    "    '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–ª–∞–¥–µ–Ω—á–µ—Å–∫–æ–π —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç–∏ (—á–∏—Å–ª–æ –¥–µ—Ç–µ–π, —É–º–µ—Ä—à–∏—Ö –≤ –≤–æ–∑—Ä–∞—Å—Ç–µ –¥–æ 1 –≥–æ–¥–∞, –Ω–∞ 1000 —Ä–æ–¥–∏–≤—à–∏—Ö—Å—è –∂–∏–≤—ã–º–∏)',\n",
    "    '–û–±—â–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç–∏ (—á–∏—Å–ª–æ —É–º–µ—Ä—à–∏—Ö –Ω–∞ 1000 —á–µ–ª–æ–≤–µ–∫ –Ω–∞—Å–µ–ª–µ–Ω–∏—è)',\n",
    "]\n",
    "\n",
    "others = [\n",
    "    \n",
    "]\n",
    "\n",
    "# –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "population = {year : –ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][neutral].copy() for year in –ù–∞—Å–µ–ª–µ–Ω–∏–µ.keys()}\n",
    "\n",
    "#########################\n",
    "clear_population = {year : –ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][neutral].copy() for year in –ù–∞—Å–µ–ª–µ–Ω–∏–µ.keys()}\n",
    "for year, data in clear_population.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][stim]\n",
    "for year, data in clear_population.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = –ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][destim]\n",
    "##########################\n",
    "\n",
    "# —Å—Ç–∏–º—É–ª—è–Ω—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "for year, data in population.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][stim]\n",
    "\n",
    "# –¥–µ—Å—Ç–∏–º—É–ª—è–Ω—Ç—ã –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è\n",
    "for year, data in population.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -–ù–∞—Å–µ–ª–µ–Ω–∏–µ[year][destim]\n",
    "\n",
    "# –¥—Ä—É–≥–∏–µ –ø–æ–∫–∞ –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b7bee06-6c06-4948-9010-b55e06fb0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "stimulants = [\n",
    "    '–í–∞–ª–æ–≤–æ–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –æ—Ö–≤–∞—Ç–∞ –¥–æ—à–∫–æ–ª—å–Ω—ã–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–π –≤ –≤–æ–∑—Ä–∞—Å—Ç–µ 1‚Äí6 –ª–µ—Ç)',\n",
    "    '–í—ã–ø—É—Å–∫ –±–∞–∫–∞–ª–∞–≤—Ä–æ–≤, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –º–∞–≥–∏—Å—Ç—Ä–æ–≤ (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–í—ã–ø—É—Å–∫ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö –∏ —Å–ª—É–∂–∞—â–∏—Ö (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–í—ã–ø—É—Å–∫ –æ–±—É—á–∞—é—â–∏—Ö—Å—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—â–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: –í—ã–ø—É—Å–∫ –æ–±—É—á–∞—é—â–∏—Ö—Å—è —Å –∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–º –æ —Å—Ä–µ–¥–Ω–µ–º –æ–±—â–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–í—ã–ø—É—Å–∫ –æ–±—É—á–∞—é—â–∏—Ö—Å—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—â–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: –í—ã–ø—É—Å–∫ –æ–±—É—á–∞—é—â–∏—Ö—Å—è —Å –∞—Ç—Ç–µ—Å—Ç–∞—Ç–æ–º –æ–± –æ—Å–Ω–æ–≤–Ω–æ–º –æ–±—â–µ–º –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–í—ã–ø—É—Å–∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–≤–µ–Ω–∞ (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–û–±–µ—Å–ø–µ—á–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–π –¥–æ—à–∫–æ–ª—å–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ –º–µ—Å—Ç–∞–º–∏ –≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –¥–æ—à–∫–æ–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –ø—Ä–∏—Å–º–æ—Ç—Ä –∏ —É—Ö–æ–¥ –∑–∞ –¥–µ—Ç—å–º–∏ (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –º–µ—Å—Ç –Ω–∞ 1000 –¥–µ—Ç–µ–π)',\n",
    "    '–ü—Ä–∏–µ–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞, —Å–ø–µ—Ü–∏–∞–ª–∏—Ç–µ—Ç–∞, –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–ü—Ä–∏–µ–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö, —Å–ª—É–∂–∞—â–∏—Ö (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ü—Ä–∏–µ–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–≤–µ–Ω–∞ (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –∞—Å–ø–∏—Ä–∞–Ω—Ç–æ–≤ (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –≤–æ—Å–ø–∏—Ç–∞–Ω–Ω–∏–∫–æ–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –¥–æ—à–∫–æ–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –ø—Ä–∏—Å–º–æ—Ç—Ä –∏ —É—Ö–æ–¥ –∑–∞ –¥–µ—Ç—å–º–∏ (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –¥–æ–∫—Ç–æ—Ä–∞–Ω—Ç–æ–≤ (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –æ–±—É—á–∞—é—â–∏—Ö—Å—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—â–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–Ω–∞ –Ω–∞—á–∞–ª–æ —É—á–µ–±–Ω–æ–≥–æ –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –æ–±—É—á–∞—é—â–∏—Ö—Å—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞, —Å–ø–µ—Ü–∏–∞–ª–∏—Ç–µ—Ç–∞, –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã (–Ω–∞ –Ω–∞—á–∞–ª–æ —É—á–µ–±–Ω–æ–≥–æ –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    # '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –æ–±—É—á–∞—é—â–∏—Ö—Å—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞, —Å–ø–µ—Ü–∏–∞–ª–∏—Ç–µ—Ç–∞, –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã –Ω–∞ 10 000 —á–µ–ª–æ–≤–µ–∫ –Ω–∞—Å–µ–ª–µ–Ω–∏—è (–Ω–∞ –Ω–∞—á–∞–ª–æ —É—á–µ–±–Ω–æ–≥–æ –≥–æ–¥–∞, —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –æ–±—É—á–∞—é—â–∏—Ö—Å—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—á–∏—Ö, —Å–ª—É–∂–∞—â–∏—Ö (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞,—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –æ–±—É—á–∞—é—â–∏—Ö—Å—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–≤–µ–Ω–∞ (–Ω–∞ –Ω–∞—á–∞–ª–æ —É—á–µ–±–Ω–æ–≥–æ –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)'\n",
    "]\n",
    "\n",
    "destimulants = [\n",
    "    '–£–¥–µ–ª—å–Ω—ã–π –≤–µ—Å –æ–±—É—á–∞—é—â–∏—Ö—Å—è –≤–æ –≤—Ç–æ—Ä—É—é –∏ —Ç—Ä–µ—Ç—å—é —Å–º–µ–Ω—ã –≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö, –æ—Å—É—â–µ—Å—Ç–≤–ª—è—é—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—â–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–Ω–∞ –Ω–∞—á–∞–ª–æ —É—á–µ–±–Ω–æ–≥–æ –≥–æ–¥–∞, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç –æ–±—â–µ–π —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±—É—á–∞—é—â–∏—Ö—Å—è)'\n",
    "]\n",
    "\n",
    "others = [\n",
    "    # —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø—Ä–∏–µ–º–∞ –∏ –≤—ã–ø—É—Å–∫–∞\n",
    "]\n",
    "\n",
    "# –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "education = {year : –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][neutral].copy() for year in –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.keys()}\n",
    "\n",
    "#########################\n",
    "clear_education = {year : –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][neutral].copy() for year in –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ.keys()}\n",
    "for year, data in clear_education.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][stim]\n",
    "for year, data in clear_education.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][destim]\n",
    "##########################\n",
    "\n",
    "# —Å—Ç–∏–º—É–ª—è–Ω—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "for year, data in education.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][stim]\n",
    "    \n",
    "    \n",
    "\n",
    "# –¥–µ—Å—Ç–∏–º—É–ª—è–Ω—Ç—ã –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è\n",
    "for year, data in education.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[year][destim]\n",
    "\n",
    "# –¥—Ä—É–≥–∏–µ –ø–æ–∫–∞ –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99142a35-9cdb-4293-8424-8156ac2ec829",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = [\n",
    "    'object_name',\n",
    "    'object_level',\n",
    "    'year'\n",
    "]\n",
    "\n",
    "# –°—Ç–∏–º—É–ª—è–Ω—Ç—ã ‚Äî –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∏—Ç—É–∞—Ü–∏–∏\n",
    "stimulants = [\n",
    "    '–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ–¥–æ–≤–æ–π —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞–Ω—è—Ç—ã—Ö (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –≥–æ–¥—É)',\n",
    "    '–ù–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–∑–∞–Ω—è—Ç–æ–≥–æ –Ω–∞—Å–µ–ª–µ–Ω–∏—è, —Å–æ—Å—Ç–æ—è—â–µ–≥–æ –Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —É—á–µ—Ç–µ –≤ –æ—Ä–≥–∞–Ω–∞—Ö —Å–ª—É–∂–±—ã –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è, –≤ —Ä–∞—Å—á–µ—Ç–µ –Ω–∞ –æ–¥–Ω—É –∑–∞—è–≤–ª–µ–Ω–Ω—É—é –≤–∞–∫–∞–Ω—Å–∏—é (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞—Ö, –∑–∞—è–≤–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è–º–∏ –≤ –æ—Ä–≥–∞–Ω—ã —Å–ª—É–∂–±—ã –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–°—Ä–µ–¥–Ω–µ–≥–æ–¥–æ–≤–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –∑–∞–Ω—è—Ç—ã—Ö (—Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–£—Ä–æ–≤–µ–Ω—å –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–£—Ä–æ–≤–µ–Ω—å –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –≤ —Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ–º –≤–æ–∑—Ä–∞—Å—Ç–µ (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–£—Ä–æ–≤–µ–Ω—å —É—á–∞—Å—Ç–∏—è –≤ —Å–æ—Å—Ç–∞–≤–µ —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)'\n",
    "]\n",
    "\n",
    "# –î–µ—Å—Ç–∏–º—É–ª—è–Ω—Ç—ã ‚Äî –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã —É–º–µ–Ω—å—à–∞—Ç—å—Å—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∏—Ç—É–∞—Ü–∏–∏\n",
    "destimulants = [\n",
    "    '–£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã: –£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã: –£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã –≤ —Ç—Ä—É–¥–æ—Å–ø–æ—Å–æ–±–Ω–æ–º –≤–æ–∑—Ä–∞—Å—Ç–µ (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–£—Ä–æ–≤–µ–Ω—å –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã: –£—Ä–æ–≤–µ–Ω—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü—ã (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –±–µ–∑—Ä–∞–±–æ—Ç–Ω—ã—Ö (–ø–æ –¥–∞–Ω–Ω—ã–º –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—á–µ–π —Å–∏–ª—ã, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–µ–∑—Ä–∞–±–æ—Ç–Ω—ã—Ö (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)',\n",
    "    '–ß–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–∑–∞–Ω—è—Ç—ã—Ö –≥—Ä–∞–∂–¥–∞–Ω, —Å–æ—Å—Ç–æ—è—â–∏—Ö –Ω–∞ —É—á–µ—Ç–µ –≤ –æ—Ä–≥–∞–Ω–∞—Ö —Å–ª—É–∂–±—ã –∑–∞–Ω—è—Ç–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –≤ —Ü–µ–ª—è—Ö –ø–æ–∏—Å–∫–∞ –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ä–∞–±–æ—Ç—ã (–Ω–∞ –∫–æ–Ω–µ—Ü –≥–æ–¥–∞, —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫)'\n",
    "]\n",
    "\n",
    "others = [\n",
    "    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n",
    "]\n",
    "\n",
    "# –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "labor = {year: –¢—Ä—É–¥[year][neutral].copy() for year in –¢—Ä—É–¥.keys()}\n",
    "\n",
    "#########################\n",
    "clear_labor = {year: –¢—Ä—É–¥[year][neutral].copy() for year in –¢—Ä—É–¥.keys()}\n",
    "for year, data in clear_labor.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –¢—Ä—É–¥[year][stim]\n",
    "for year, data in clear_labor.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = –¢—Ä—É–¥[year][destim]\n",
    "##########################\n",
    "\n",
    "# –°—Ç–∏–º—É–ª—è–Ω—Ç—ã –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å\n",
    "for year, data in labor.items():\n",
    "    for stim in stimulants:\n",
    "        data[stim] = –¢—Ä—É–¥[year][stim]\n",
    "    \n",
    "# –î–µ—Å—Ç–∏–º—É–ª—è–Ω—Ç—ã –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É—é—Ç—Å—è\n",
    "for year, data in labor.items():\n",
    "    for destim in destimulants:\n",
    "        data[destim] = -–¢—Ä—É–¥[year][destim]\n",
    "\n",
    "# –î—Ä—É–≥–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–∫–∞ –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6ad656b-74a4-4a31-a644-27b759286e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–≥–∏–æ–Ω—ã\n",
    "population = {year : population[year][population[year]['object_level'] == '—Ä–µ–≥–∏–æ–Ω'] for year in population.keys()}\n",
    "clear_population = {year : clear_population[year][clear_population[year]['object_level'] == '—Ä–µ–≥–∏–æ–Ω'] for year in clear_population.keys()}\n",
    "\n",
    "education = {year : education[year][education[year]['object_level'] == '—Ä–µ–≥–∏–æ–Ω'] for year in education.keys()}\n",
    "clear_education = {year : clear_education[year][clear_education[year]['object_level'] == '—Ä–µ–≥–∏–æ–Ω'] for year in clear_education.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9dd9624e-ef09-443d-994f-05a8a6f0fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in population.items():\n",
    "    population[year] = drop_missing_values(df, population[list(population.keys())[0]].columns)\n",
    "for year, df in clear_population.items():\n",
    "    clear_population[year] = drop_missing_values(df, clear_population[list(clear_population.keys())[0]].columns)\n",
    "\n",
    "\n",
    "for year, df in education.items():\n",
    "    education[year] = drop_missing_values(df, education[list(education.keys())[0]].columns)\n",
    "for year, df in clear_education.items():\n",
    "    clear_education[year] = drop_missing_values(df, clear_education[list(clear_education.keys())[0]].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de9659de-d3b6-48a8-8fbd-2af24a061a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_hdf5(data: dict[int, pd.DataFrame], filename: str):\n",
    "#     with pd.HDFStore(filename, mode=\"w\") as store:\n",
    "#         for year, df in data.items():\n",
    "#             store.put(f\"year_{year}\", df)\n",
    "\n",
    "# def load_hdf5(filename: str) -> dict[int, pd.DataFrame]:\n",
    "#     data = {}\n",
    "#     with pd.HDFStore(filename, mode=\"r\") as store:\n",
    "#         for key in store.keys():\n",
    "#             year = int(key.split(\"_\")[1])  # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥ –∏–∑ –∫–ª—é—á–∞\n",
    "#             data[year] = store[key]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef82b7f6-955e-443d-a577-91f62f75ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978d399332da4a1db2205c5923c8deea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='–î–æ–º–µ–Ω:', options=('–ù–∞—Å–µ–ª–µ–Ω–∏–µ', '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ'), value='–ù–∞—Å–µ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domen_mapping = {\n",
    "    \"–ù–∞—Å–µ–ª–µ–Ω–∏–µ\": (\"population\", \"clear_population\"),\n",
    "    \"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\": (\"education\", \"clear_education\"),\n",
    "}\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–æ–º–µ–Ω–∞\n",
    "domen_widget = widgets.Dropdown(\n",
    "    options=domen_mapping.keys(),\n",
    "    description='–î–æ–º–µ–Ω:'\n",
    ")\n",
    "\n",
    "# –í–∏–¥–∂–µ—Ç—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "region_widget = widgets.Dropdown(\n",
    "    options=[],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –¥–æ–º–µ–Ω–∞\n",
    "    description='–†–µ–≥–∏–æ–Ω:'\n",
    ")\n",
    "\n",
    "method_calculation_widget = widgets.Dropdown(\n",
    "    options = ['PCA', '–û–±—Ä–∞—Ç–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è', '–†–∞–≤–Ω—ã–µ –≤–µ—Å–∞'],\n",
    "    value='PCA',  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - PCA\n",
    "    description='–ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞:'\n",
    ")\n",
    "\n",
    "base_year_widget = widgets.IntSlider(\n",
    "    value=2010,\n",
    "    min=2000,\n",
    "    max=2022,\n",
    "    step=1,\n",
    "    description='–ë–∞–∑–æ–≤—ã–π –≥–æ–¥:'\n",
    ")\n",
    "\n",
    "index_share_widget = widgets.FloatSlider(\n",
    "    value=0.9,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Alpha:'\n",
    ")\n",
    "\n",
    "# –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
    "load_domen_button = widgets.Button(description=\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –î–æ–º–µ–Ω\", button_style='primary')\n",
    "interactive_analysis_button = widgets.Button(description=\"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ê–Ω–∞–ª–∏–∑\", button_style='info')\n",
    "update_button = widgets.Button(description=\"–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ\", button_style='success')\n",
    "show_table_button = widgets.Button(description=\"–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É\", button_style='success')\n",
    "\n",
    "# –ü–æ–ª—è –≤—ã–≤–æ–¥–∞\n",
    "output_domen = widgets.Output()\n",
    "output_interactive = widgets.Output()\n",
    "output_main = widgets.Output()\n",
    "output_table = widgets.Output()\n",
    "\n",
    "# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
    "domen = None\n",
    "clear_domen = None\n",
    "domen_name = \"\"\n",
    "region_name = \"\"\n",
    "method_calculation = 1\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –≤—ã–±–æ—Ä–∞ –¥–æ–º–µ–Ω–∞\n",
    "def load_domen(_=None):\n",
    "    global domen, clear_domen, domen_name, region_name\n",
    "    domen_key = domen_widget.value\n",
    "    domen_var, clear_domen_var = domen_mapping[domen_key]  # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
    "\n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
    "    domen = globals()[domen_var]\n",
    "    clear_domen = globals()[clear_domen_var]\n",
    "    domen_name = domen_key  # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –∏–º—è –¥–æ–º–µ–Ω–∞\n",
    "\n",
    "    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤\n",
    "    region_widget.options = domen[list(domen.keys())[0]]['object_name'].unique()\n",
    "\n",
    "    output_domen.clear_output()\n",
    "    with output_domen:\n",
    "        print(f\"–í—ã–±—Ä–∞–Ω –¥–æ–º–µ–Ω: {domen_name}\")\n",
    "\n",
    "load_domen_button.on_click(load_domen)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n",
    "def interactive_analysis(_=None):\n",
    "    global clear_domen\n",
    "    output_interactive.clear_output()\n",
    "    with output_interactive:\n",
    "        analyze_indicator_interactive(clear_domen)\n",
    "\n",
    "interactive_analysis_button.on_click(interactive_analysis)\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "def process_data(_=None):\n",
    "    global domen, clear_domen, domen_name, region_name, method_calculation\n",
    "\n",
    "    if domen is None:\n",
    "        return\n",
    "    region_name = region_widget.value\n",
    "    base_year = base_year_widget.value\n",
    "    index_share = index_share_widget.value\n",
    "    calculation_method = {'PCA' : 1, '–û–±—Ä–∞—Ç–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è' : 2, '–†–∞–≤–Ω—ã–µ –≤–µ—Å–∞' : 3}\n",
    "    method_calculation = calculation_method[method_calculation_widget.value]\n",
    "\n",
    "    output_main.clear_output()\n",
    "\n",
    "    with output_main:\n",
    "        print(f\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞: {region_name}, –±–∞–∑–æ–≤—ã–π –≥–æ–¥: {base_year}, –∏–Ω–¥–µ–∫—Å: {index_share}\")\n",
    "\n",
    "        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–≥–∏–æ–Ω—É\n",
    "        domen_filtered = {year: domen[year][domen[year]['object_level'] == '—Ä–µ–≥–∏–æ–Ω'] for year in domen.keys()}\n",
    "\n",
    "        # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "        for year, df in domen_filtered.items():\n",
    "            domen_filtered[year] = drop_missing_values(df, domen_filtered[list(domen_filtered.keys())[0]].columns)\n",
    "\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ç–µ–∫—É—â–µ–º—É –≥–æ–¥—É –∏ –±–∞–∑–æ–≤–æ–º—É –≥–æ–¥—É\n",
    "        domen_norm_by_current = normalized_dict_by_minmax(domen_filtered)\n",
    "        domen_norm_by_base = normalized_dict_by_minmax_by_base_year(domen_filtered, base_year)\n",
    "\n",
    "        # –†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ –≤–µ—Å–æ–≤\n",
    "        domen_indexes_by_base, weights_by_base = calculate_index_with_weights(domen_norm_by_base, method_calculation)\n",
    "        domen_indexes_by_current, weights_by_current = calculate_index_with_weights(domen_norm_by_current, method_calculation)\n",
    "\n",
    "        # –§–∏–Ω–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å\n",
    "        domen_final = combine_indices(domen_indexes_by_base, domen_indexes_by_current, index_share)\n",
    "\n",
    "        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "        plot_index_trends_multi(domen_indexes_by_base, domen_indexes_by_current, domen_final, region_name, domen_name)\n",
    "        plot_index_trends_with_similar(domen_indexes_by_base, domen_indexes_by_current, domen_final, region_name, domen_name, 3)\n",
    "        plot_top_successful_regions_dynamic(domen_final, domen_name, 15, 0.1)\n",
    "        plot_bottom_successful_regions_dynamic(domen_final, domen_name, 15, 0.1)\n",
    "\n",
    "        # –û—Ü–µ–Ω–∫–∞ –≤–ª–∏—è–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n",
    "        domen_norm_base_weighted = {year: count_impact_per_component(domen_norm_by_base[year], weights_by_base) for year in domen_norm_by_base.keys()}\n",
    "        domen_norm_current_weighted = {year: count_impact_per_component(domen_norm_by_current[year], weights_by_current) for year in domen_norm_by_current.keys()}\n",
    "        global importances_of_domen\n",
    "        importances_of_domen = combine_for_weights_and_importances(domen_norm_base_weighted, domen_norm_current_weighted, index_share)\n",
    "\n",
    "update_button.on_click(process_data)\n",
    "\n",
    "year_widget = widgets.IntSlider(\n",
    "    value=2000,\n",
    "    min=2000,\n",
    "    max=2022,\n",
    "    step=1,\n",
    "    description='–ì–æ–¥:'\n",
    ")\n",
    "\n",
    "def show_table(_=None):\n",
    "    # –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "    output_main.clear_output()\n",
    "\n",
    "    output_table.clear_output()\n",
    "    with output_table:\n",
    "        selected_year = year_widget.value  # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥\n",
    "        print(f\"–ò–Ω–¥–µ–∫—Å —Ä–µ–≥–∏–æ–Ω–∞: {region_widget.value}, –ì–æ–¥: {selected_year}\")  # –í—ã–≤–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Ä–µ–≥–∏–æ–Ω–∞ –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥\n",
    "        df_importances = rank_importances(clear_domen, domen, importances_of_domen, region_widget.value, selected_year)\n",
    "        display(df_importances)\n",
    "\n",
    "show_table_button.on_click(show_table)\n",
    "\n",
    "clear_screen_button = widgets.Button(description=\"–û—á–∏—Å—Ç–∏—Ç—å —ç–∫—Ä–∞–Ω\", button_style='danger')\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ —ç–∫—Ä–∞–Ω–∞\n",
    "def clear_screen(_=None):\n",
    "    # –û—á–∏—â–∞–µ–º –≤—Å–µ –æ–±–ª–∞—Å—Ç–∏ –≤—ã–≤–æ–¥–∞\n",
    "    output_domen.clear_output()\n",
    "    output_interactive.clear_output()\n",
    "    output_main.clear_output()\n",
    "    output_table.clear_output()\n",
    "\n",
    "clear_screen_button.on_click(clear_screen)\n",
    "\n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —Å –∫–Ω–æ–ø–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ —ç–∫—Ä–∞–Ω–∞\n",
    "display(VBox([\n",
    "    HBox([domen_widget, load_domen_button]),\n",
    "    output_domen,\n",
    "    interactive_analysis_button,\n",
    "    output_interactive,\n",
    "    HBox([region_widget, base_year_widget, index_share_widget]),\n",
    "    HBox([update_button, method_calculation_widget]),\n",
    "    show_table_button,\n",
    "    year_widget,  # –ù–æ–≤—ã–π –≤–∏–¥–∂–µ—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ–¥–∞\n",
    "    output_main,\n",
    "    output_table,\n",
    "    clear_screen_button  # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –æ—á–∏—Å—Ç–∫–∏ —ç–∫—Ä–∞–Ω–∞\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d2699-bd4c-4a8a-aadc-e238d2c1b36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f95e99-efb4-45c0-9d0b-8bdc6e0289dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203d6f8-b596-453e-b664-824b2c057c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939744e-ab03-4bde-a839-f84afd826cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
